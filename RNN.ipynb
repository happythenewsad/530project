{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, \"./rnn\")\n",
    "import train\n",
    "import model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# need stuff from main.py to test transformation into Tensors\n",
    "\n",
    "def normalize(column_name, df):\n",
    "    std = df[column_name].std()\n",
    "    norm_col = df[column_name].apply(lambda x: x - std)\n",
    "    df[column_name] = norm_col\n",
    "\n",
    "# builds the labels and vectorizations of given data\n",
    "#if you want to fool around with including/excluding certain features and whatnot, this is the place to do it\n",
    "\n",
    "def labels_and_vectors(file, index=0):\n",
    "    df = pd.read_pickle(file)\n",
    "    \n",
    "    wordlist = VulgarExtractor.vulgarWords(\"feature-extraction/vulgar-extractor/badwords.txt\") \n",
    "    dftext = df[['text']]\n",
    "    result = dftext.applymap(lambda x: VulgarExtractor.containsVulgar(x,wordlist))\n",
    "    df['isVulgar'] = result\n",
    "\n",
    "    #word_embeddings = [ee.tweetVec(tagged_line) for tagged_line in df['text']]\n",
    "    textlist = [txt.replace('\\n','') for txt in df['text'].tolist()]\n",
    "    tagged_sents = TwitterParser.tag(textlist)\n",
    "    df['POS'] = tagged_sents\n",
    "\n",
    "    processed_sents = []\n",
    "    for tagged_sent in df['POS']:\n",
    "        processed_words = []\n",
    "        for word, tag in tagged_sent:\n",
    "            if tag == 'U':\n",
    "                processed_words.append('someurl')\n",
    "            elif tag == '@':\n",
    "                processed_words.append('@someuser')\n",
    "            else:\n",
    "                processed_words.append(word)\n",
    "        sent = ' '.join(processed_words)\n",
    "        processed_sents.append(sent)\n",
    "    df['text'] = processed_sents\n",
    "\n",
    "    word_counts = [TwitterParser.word_count(tagged_line) for tagged_line in df['POS']]\n",
    "    pos_count_list = [TwitterParser.pos_counts(tagged_line) for tagged_line in df['POS']]\n",
    "    contains_adjs = [TwitterParser.contains_adjectives(tagged_line) for tagged_line in df['POS']]\n",
    "    contains_urls = [TwitterParser.contains_url(tagged_line) for tagged_line in df['POS']]\n",
    "    contains_emojis = [TwitterParser.contains_emoji(tagged_line) for tagged_line in df['POS']]\n",
    "    contains_abbrevs = [TwitterParser.contains_abbreviation(tagged_line) for tagged_line in df['POS']]\n",
    "\n",
    "    df['wordCount'] = word_counts\n",
    "    df['posCounts'] = pos_count_list\n",
    "    df['containsAdjective'] = contains_adjs\n",
    "    df['containsURL'] = contains_urls\n",
    "    df['containsEmoji'] = contains_emojis\n",
    "    df['containsAbbreviation'] = contains_abbrevs\n",
    "    #df['wordEmbedding'] = word_embeddings\n",
    "\n",
    "\n",
    "    for i, tag in enumerate(TwitterParser.tagset):\n",
    "        tag_counts = []\n",
    "        for pos_counts in df['posCounts']:\n",
    "            tag_counts.append(pos_counts[i])\n",
    "        column_name = 'num_' + tag\n",
    "        df[column_name] = tag_counts\n",
    "        normalize(column_name, df)\n",
    "        \n",
    "    # Changes \"true\"/\"false\"/\"unverified\" to numeric values, just like the in the early cells\n",
    "\n",
    "    df.loc[df.classification == 'true', 'classification'] = 1\n",
    "    df.loc[df.classification == 'false', 'classification'] = 2\n",
    "    df.loc[df.classification == 'unverified', 'classification'] = 0\n",
    "    # getting the labels\n",
    "\n",
    "    #removed containsURL\n",
    "    attributes = ['isVulgar', 'containsAdjective', 'containsEmoji', 'containsAbbreviation', 'wordCount']\n",
    "    for tag in TwitterParser.tagset:\n",
    "        attributes.append('num_' + tag)\n",
    "\n",
    "    labels = df['classification']\n",
    "    labels = [l for l in labels]\n",
    "    labels = np.array(labels)\n",
    "\n",
    "\n",
    "    # getting the values as a list of lists\n",
    "    values = df[attributes].values.tolist()\n",
    "    word_embedding_values = df['wordEmbedding'].values.tolist()\n",
    "\n",
    "\n",
    "    #Below puts the tweet ID as a feature. Comment this out if you aren't using tweetID\n",
    "    ###for i,index in enumerate(df.index):\n",
    "    ###    dev_values[i].append(int(index))\n",
    "\n",
    "\n",
    "# UNCOMMENT THIS IN ORDER TO INCOPORATE WORD_EMBEDDINGS AGAIN\n",
    "    #for i,d in enumerate(word_embedding_values):\n",
    "     #   values[i].extend(d)\n",
    "\n",
    "    values = np.array(values)\n",
    "    if index == 1:\n",
    "        return df.index, values\n",
    "\n",
    "    return labels, values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 553480082996879360\n",
      "\n",
      " 581153923987206146\n",
      "\n",
      " 500298588992593920\n",
      "\n",
      " 552788945017516032\n",
      "\n",
      " 524948206023880704\n",
      "\n",
      " 553561170637238272\n",
      "\n",
      " 758159624122097664\n",
      "\n",
      " 767725956706414592\n",
      "\n",
      " 580352273001410560\n",
      "\n",
      " 581359544682614784\n",
      "\n",
      " 763098277986209792\n",
      "\n",
      " 581290271997968384\n",
      "\n",
      " 775057555865206784\n",
      "\n",
      " 500280249629036544\n",
      "\n",
      " 498293668655423488\n",
      "\n",
      " 774991078265094144\n",
      "\n",
      " 553553288625672192\n",
      "\n",
      " 524961721744900097\n",
      "\n",
      " 524941720249978880\n",
      "\n",
      " 544294893146091520\n",
      "\n",
      " 768859780240773121\n",
      "\n",
      " 764927075522260992\n",
      "\n",
      " 544274544174071809\n",
      "\n",
      " 498486826269548545\n",
      "\n",
      " 544315472075042818\n",
      "\n",
      " 524923293711998976\n",
      "\n",
      " 769988636754505729\n",
      "\n",
      " 524936793633083394\n",
      "\n",
      " 553480082996879360\n",
      "\n",
      " 581153923987206146\n",
      "\n",
      " 500298588992593920\n",
      "\n",
      " 552788945017516032\n",
      "\n",
      " 524948206023880704\n",
      "\n",
      " 553561170637238272\n",
      "\n",
      " 758159624122097664\n",
      "\n",
      " 767725956706414592\n",
      "\n",
      " 580352273001410560\n",
      "\n",
      " 581359544682614784\n",
      "\n",
      " 763098277986209792\n",
      "\n",
      " 581290271997968384\n",
      "\n",
      " 775057555865206784\n",
      "\n",
      " 500280249629036544\n",
      "\n",
      " 498293668655423488\n",
      "\n",
      " 774991078265094144\n",
      "\n",
      " 553553288625672192\n",
      "\n",
      " 524961721744900097\n",
      "\n",
      " 524941720249978880\n",
      "\n",
      " 544294893146091520\n",
      "\n",
      " 768859780240773121\n",
      "\n",
      " 764927075522260992\n",
      "\n",
      " 544274544174071809\n",
      "\n",
      " 498486826269548545\n",
      "\n",
      " 544315472075042818\n",
      "\n",
      " 524923293711998976\n",
      "\n",
      " 769988636754505729\n",
      "\n",
      " 524936793633083394\n",
      "saving data to output..\n"
     ]
    }
   ],
   "source": [
    "from FileReader import FileReader\n",
    "classInstance = FileReader\n",
    "classInstance.get_dataframe() #IMPORTANT:  saves a pickle to output/simple or output/full. \n",
    "import sys\n",
    "sys.path.insert(1, \"./feature-extraction/embed-extractor\")\n",
    "#from EmbedExtractor import EmbedExtractor\n",
    "sys.path.insert(1, \"./feature-extraction/vulgar-extractor\")\n",
    "from VulgarExtractor import VulgarExtractor\n",
    "sys.path.insert(1, \"./feature-extraction/twitter-parser\")\n",
    "from TwitterParser import TwitterParser\n",
    "import classifiers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "#ee = EmbedExtractor()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-264-2569c44faf66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'head'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr_labels, tr_values = labels_and_vectors('output/simple/train_data_simple.pickle')\n",
    "indices, dev_values,= labels_and_vectors('output/simple/dev_data_simple.pickle', index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## convert to tensor Variable here\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import helpers\n",
    "from torch.autograd import Variable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-246-f2179da2ca41>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-246-f2179da2ca41>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    hidden_size = = 50\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 2000\n",
    "hidden_size = 20\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "decoder = model.RNN(len(tr_values[0]), hidden_size=hidden_size, output_size =3)\n",
    "# Loss function can be changed as an argument?\n",
    "decoder_optimizer = torch.optim.SGD(decoder.parameters(), learning_rate)\n",
    "\n",
    "criterion = nn.NLLLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tvs = [arr.tolist() for arr in tr_values]\n",
    "dvs = [arr.tolist() for arr in tr_values]\n",
    "\n",
    "tls = [l.item() for l in tr_labels]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 15.0,\n",
       " 1.2109006780606513,\n",
       " 0.39595863979681123,\n",
       " -0.20718062552047917,\n",
       " 0.344229689792404,\n",
       " -0.2572742445336669,\n",
       " -0.21372359007418834,\n",
       " 0.0,\n",
       " 1.2859161772475212,\n",
       " -0.9559925467866434,\n",
       " -0.7252163737807164,\n",
       " -0.1586364050526587,\n",
       " 1.8704734362120636,\n",
       " 1.619042495490964,\n",
       " -0.42161521306517785,\n",
       " -0.2894338912872113,\n",
       " -0.15863640505265839,\n",
       " 0.0,\n",
       " 0.2610795953247669,\n",
       " -0.37429841758257326,\n",
       " -0.22428527680566782,\n",
       " -0.7620584777480716,\n",
       " 0.0,\n",
       " -0.6633118686714934,\n",
       " 0.5677896821287431,\n",
       " -0.13457721463346745]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vector_to_tensor(vector):\n",
    "    tensor = torch.zeros(1, len(tvs[0]))\n",
    "    for j in range(len(vector)):\n",
    "        tensor[0][j] = vector[j]\n",
    "    return tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-262-f325fe70ff76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvector_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtvs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m141\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'classification'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "tensor = vector_to_tensor(tvs[141])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_all():\n",
    "    for i, label in enumerate(tls):\n",
    "        tensor = vector_to_tensor(tvs[i])  \n",
    "        category_tensor = Variable(torch.LongTensor([label]))\n",
    "        line_tensor = Variable(torch.FloatTensor(tensor))\n",
    "        output, loss = train.train(category_tensor, line_tensor, decoder)\n",
    "        decoder_optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from the pytorch tutroial\n",
    "\n",
    "\n",
    "# Print epoch number, loss, name and guess\n",
    "# validation_loss = 0\n",
    "# for key in category_lines_val.keys():\n",
    "# lines = category_lines_val[key]\n",
    "#         #total_count += len(lines)\n",
    "#             for ln in lines:\n",
    "#             output = evaluate(Variable(line_to_tensor(ln)))\n",
    "#             category_tensor = Variable(torch.LongTensor([all_categories.index(key)]))\n",
    "#             validation_loss += criterion(output, category_tensor)\n",
    "#     validation_losses.append(validation_loss/900)\n",
    "\n",
    "#     guess, guess_i = category_from_output(output)\n",
    "#     correct = '✓' if guess == category else '✗ (%s)' % category\n",
    "#     print('%d %d%% (%s) %.4f %s / %s %s' % (epoch, epoch / n_epochs * 100, time_since(start), loss, line, guess, correct))\n",
    "for i in range(100):\n",
    "    train_all()\n",
    "\n",
    "\n",
    "predictions=[]\n",
    "\n",
    "for d in dvs:\n",
    "    tensor = vector_to_tensor(d)  \n",
    "    line_tensor = Variable(torch.FloatTensor(tensor))\n",
    "    output = decoder.predict(line_tensor)\n",
    "    predictions.append(output)\n",
    "    \n",
    "\n",
    "#print(predictions)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  2\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  2\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  2\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  2\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  2\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  2\n",
       " [torch.LongTensor of size 1x1], \n",
       "  2\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  2\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  2\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  2\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  2\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  0\n",
       " [torch.LongTensor of size 1x1], \n",
       "  1\n",
       " [torch.LongTensor of size 1x1]]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'580319078155468800': ('unverified', 1),\n",
       " '580319184652890113': ('unverified', 1),\n",
       " '580320684305416192': ('unverified', 1),\n",
       " '580321156508577792': ('unverified', 1),\n",
       " '580322453928431617': ('unverified', 1),\n",
       " '580323060533764097': ('unverified', 1),\n",
       " '580324027715063808': ('false', 1),\n",
       " '580325090367315968': ('unverified', 1),\n",
       " '580326222107951104': ('unverified', 1),\n",
       " '580331561398108160': ('true', 1),\n",
       " '580332109782466561': ('unverified', 1),\n",
       " '580333763512705025': ('unverified', 1),\n",
       " '580333909008871424': ('true', 1),\n",
       " '580339547269144576': ('true', 1),\n",
       " '580339825649291264': ('unverified', 1),\n",
       " '580340476949086208': ('unverified', 1),\n",
       " '580348081100734464': ('true', 1),\n",
       " '580360165540642816': ('true', 1),\n",
       " '580371845997682688': ('true', 1),\n",
       " '580882341880446977': ('true', 1),\n",
       " '581047170637381632': ('unverified', 1),\n",
       " '581063377226637312': ('unverified', 1),\n",
       " '581293286268129280': ('unverified', 1),\n",
       " '581386094337474560': ('unverified', 1),\n",
       " '581473088249958400': ('unverified', 1)}"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps = []\n",
    "\n",
    "for i, p in enumerate(predictions):\n",
    "    p = p[0][0]\n",
    "    if p == 2:\n",
    "        ps.append('false')\n",
    "    if p == 1:\n",
    "        ps.append('true')\n",
    "    if p == 0:\n",
    "        ps.append('unverified')\n",
    "\n",
    "pred_dict = {index:(ps[i],1) for i,index in enumerate(indices)}\n",
    "pred_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('output/rnn/tr_test.json', 'w') as outfile:\n",
    "    json.dump(pred_dict, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 entries in reference file\r\n",
      "matching entry: 580325090367315968\r\n",
      "matching entry: 580348081100734464\r\n",
      "matching entry: 580324027715063808\r\n",
      "matching entry: 580319184652890113\r\n",
      "matching entry: 580333909008871424\r\n",
      "matching entry: 580321156508577792\r\n",
      "matching entry: 580320684305416192\r\n",
      "matching entry: 580333763512705025\r\n",
      "matching entry: 580340476949086208\r\n",
      "matching entry: 580339825649291264\r\n",
      "matching entry: 580360165540642816\r\n",
      "matching entry: 580322453928431617\r\n",
      "matching entry: 580882341880446977\r\n",
      "matching entry: 580326222107951104\r\n",
      "matching entry: 581473088249958400\r\n",
      "matching entry: 580371845997682688\r\n",
      "matching entry: 580331561398108160\r\n",
      "matching entry: 581047170637381632\r\n",
      "matching entry: 581293286268129280\r\n",
      "matching entry: 580332109782466561\r\n",
      "matching entry: 580319078155468800\r\n",
      "matching entry: 580339547269144576\r\n",
      "matching entry: 581386094337474560\r\n",
      "matching entry: 581063377226637312\r\n",
      "matching entry: 580323060533764097\r\n",
      "25 matched entries in submission\r\n",
      "25 entries in reference file\r\n",
      "veracity accuracy: 0.28\r\n",
      "Micro F1: 0.28\r\n",
      "confidence rmse:   0.848528137423857\r\n"
     ]
    }
   ],
   "source": [
    "!python3 scorer/score.py data/semeval2017-task8-dataset/traindev/rumoureval-subtaskB-dev.json output/rnn/tr_test.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
