{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating features..\n",
      "\n",
      " 553480082996879360\n",
      "\n",
      " 581153923987206146\n",
      "\n",
      " 500298588992593920\n",
      "\n",
      " 552788945017516032\n",
      "\n",
      " 524948206023880704\n",
      "\n",
      " 553561170637238272\n",
      "\n",
      " 758159624122097664\n",
      "\n",
      " 767725956706414592\n",
      "\n",
      " 580352273001410560\n",
      "\n",
      " 581359544682614784\n",
      "\n",
      " 763098277986209792\n",
      "\n",
      " 581290271997968384\n",
      "\n",
      " 775057555865206784\n",
      "\n",
      " 500280249629036544\n",
      "\n",
      " 498293668655423488\n",
      "\n",
      " 774991078265094144\n",
      "\n",
      " 553553288625672192\n",
      "\n",
      " 524961721744900097\n",
      "\n",
      " 524941720249978880\n",
      "\n",
      " 544294893146091520\n",
      "\n",
      " 768859780240773121\n",
      "\n",
      " 764927075522260992\n",
      "\n",
      " 544274544174071809\n",
      "\n",
      " 498486826269548545\n",
      "\n",
      " 544315472075042818\n",
      "\n",
      " 524923293711998976\n",
      "\n",
      " 769988636754505729\n",
      "\n",
      " 524936793633083394\n",
      "\n",
      " 553480082996879360\n",
      "\n",
      " 581153923987206146\n",
      "\n",
      " 500298588992593920\n",
      "\n",
      " 552788945017516032\n",
      "\n",
      " 524948206023880704\n",
      "\n",
      " 553561170637238272\n",
      "\n",
      " 758159624122097664\n",
      "\n",
      " 767725956706414592\n",
      "\n",
      " 580352273001410560\n",
      "\n",
      " 581359544682614784\n",
      "\n",
      " 763098277986209792\n",
      "\n",
      " 581290271997968384\n",
      "\n",
      " 775057555865206784\n",
      "\n",
      " 500280249629036544\n",
      "\n",
      " 498293668655423488\n",
      "\n",
      " 774991078265094144\n",
      "\n",
      " 553553288625672192\n",
      "\n",
      " 524961721744900097\n",
      "\n",
      " 524941720249978880\n",
      "\n",
      " 544294893146091520\n",
      "\n",
      " 768859780240773121\n",
      "\n",
      " 764927075522260992\n",
      "\n",
      " 544274544174071809\n",
      "\n",
      " 498486826269548545\n",
      "\n",
      " 544315472075042818\n",
      "\n",
      " 524923293711998976\n",
      "\n",
      " 769988636754505729\n",
      "\n",
      " 524936793633083394\n",
      "saving data to output..\n",
      "test code: sample of dev data (simple version) \n",
      "\n",
      "                   classification  \\\n",
      "580319078155468800           true   \n",
      "580319184652890113          false   \n",
      "580320684305416192     unverified   \n",
      "580321156508577792          false   \n",
      "580322453928431617          false   \n",
      "580323060533764097           true   \n",
      "580324027715063808           true   \n",
      "580325090367315968     unverified   \n",
      "580326222107951104          false   \n",
      "580331561398108160          false   \n",
      "\n",
      "                                                         context_path  \\\n",
      "580319078155468800                                                NaN   \n",
      "580319184652890113                                                NaN   \n",
      "580320684305416192                                                NaN   \n",
      "580321156508577792                                                NaN   \n",
      "580322453928431617                                                NaN   \n",
      "580323060533764097                                                NaN   \n",
      "580324027715063808  ./semeval2017-task8-dataset/rumoureval-data/ge...   \n",
      "580325090367315968  ./semeval2017-task8-dataset/rumoureval-data/ge...   \n",
      "580326222107951104  ./semeval2017-task8-dataset/rumoureval-data/ge...   \n",
      "580331561398108160  ./semeval2017-task8-dataset/rumoureval-data/ge...   \n",
      "\n",
      "                   has_context  \\\n",
      "580319078155468800           0   \n",
      "580319184652890113           0   \n",
      "580320684305416192           0   \n",
      "580321156508577792           0   \n",
      "580322453928431617           0   \n",
      "580323060533764097           0   \n",
      "580324027715063808           1   \n",
      "580325090367315968           1   \n",
      "580326222107951104           1   \n",
      "580331561398108160           1   \n",
      "\n",
      "                                                                 text  \\\n",
      "580319078155468800  Germanwings Airbus A320 crashes in French Alps...   \n",
      "580319184652890113  BREAKING: 148 passengers were on board #German...   \n",
      "580320684305416192  Accident aircraft looks to be Germanwings (Air...   \n",
      "580321156508577792  Now hearing 148 passengers + crew on board the...   \n",
      "580322453928431617  German Wings airline tweeting now about report...   \n",
      "580323060533764097  Germanwings passenger plane crashes in France:...   \n",
      "580324027715063808  JUST IN: Germanwings plane crashes in southern...   \n",
      "580325090367315968  Flight #4U9525 initially climbed to 38,000 fee...   \n",
      "580326222107951104  Heart goes out to 148 passengers and crew of G...   \n",
      "580331561398108160  1047 call: DGAC source says pilots called Â«urg...   \n",
      "\n",
      "                         topic  opinion  \n",
      "580319078155468800        true        0  \n",
      "580319184652890113       false        0  \n",
      "580320684305416192  unverified        0  \n",
      "580321156508577792       false        0  \n",
      "580322453928431617       false        0  \n",
      "580323060533764097        true        0  \n",
      "580324027715063808        true        1  \n",
      "580325090367315968  unverified        0  \n",
      "580326222107951104       false        0  \n",
      "580331561398108160       false        0  \n"
     ]
    }
   ],
   "source": [
    "exec(open('file_reader.py').read())\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, \"./feature-extraction/twitter-features\")\n",
    "from EmbedExtractor import EmbedExtractor\n",
    "from VulgarExtractor import VulgarExtractor\n",
    "\n",
    "ee = EmbedExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordlist = VulgarExtractor.vulgarWords(\"badwords.txt\") \n",
    "dftext = df[['text']]\n",
    "result = dftext.applymap(lambda x: VulgarExtractor.containsVulgar(x,wordlist))\n",
    "df['isVulgar'] = result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#word embeddings must be generated before POS\n",
    "word_embeddings = [ee.tweetVec(tagged_line) for tagged_line in df['text']]\n",
    "\n",
    "from TwitterParser import TwitterParser\n",
    "textlist = [txt.replace('\\n','') for txt in df['text'].tolist()]\n",
    "tagged_sents = TwitterParser.tag(textlist)\n",
    "df['POS'] = tagged_sents\n",
    "#df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "processed_sents = []\n",
    "for tagged_sent in df['POS']:\n",
    "    processed_words = []\n",
    "    for word, tag in tagged_sent:\n",
    "        if tag == 'U':\n",
    "            processed_words.append('someurl')\n",
    "        elif tag == '@':\n",
    "            processed_words.append('@someuser')\n",
    "        else:\n",
    "            processed_words.append(word)\n",
    "    sent = ' '.join(processed_words)\n",
    "    processed_sents.append(sent)\n",
    "df['text'] = processed_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(column_name):\n",
    "    std = df[column_name].std()\n",
    "    norm_col = df[column_name].apply(lambda x: x - std)\n",
    "    df[column_name] = norm_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import TwitterParser features\n",
    "word_counts = [TwitterParser.word_count(tagged_line) for tagged_line in df['POS']]\n",
    "pos_count_list = [TwitterParser.pos_counts(tagged_line) for tagged_line in df['POS']]\n",
    "contains_adjs = [TwitterParser.contains_adjectives(tagged_line) for tagged_line in df['POS']]\n",
    "contains_urls = [TwitterParser.contains_url(tagged_line) for tagged_line in df['POS']]\n",
    "contains_emojis = [TwitterParser.contains_emoji(tagged_line) for tagged_line in df['POS']]\n",
    "contains_abbrevs = [TwitterParser.contains_abbreviation(tagged_line) for tagged_line in df['POS']]\n",
    "\n",
    "# get word count and normalize\n",
    "df['wordCount'] = word_counts\n",
    "normalize('wordCount')\n",
    "\n",
    "# get an indexed list of pos tag counts\n",
    "df['posCounts'] = pos_count_list\n",
    "\n",
    "# get binary features\n",
    "df['containsAdjective'] = contains_adjs\n",
    "df['containsURL'] = contains_urls\n",
    "df['containsEmoji'] = contains_emojis\n",
    "df['containsAbbreviation'] = contains_abbrevs\n",
    "df['wordEmbedding'] = word_embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, tag in enumerate(TwitterParser.tagset):\n",
    "    tag_counts = []\n",
    "    for pos_counts in df['posCounts']:\n",
    "        tag_counts.append(pos_counts[i])\n",
    "    column_name = 'num_' + tag\n",
    "    df[column_name] = tag_counts\n",
    "    normalize(column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.classification == 'true', 'classification'] = 1\n",
    "df.loc[df.classification == 'false', 'classification'] = 0\n",
    "df.loc[df.classification == 'unverified', 'classification'] = 2\n",
    "\n",
    "\n",
    "attributes = []\n",
    "# getting the labels\n",
    "# You have to comment this out if you want only tweet ID to be in the features. \n",
    "# Note that by doing this, you will screw up the simple/tr,simple/dev test located after this\n",
    "\n",
    "\n",
    "attributes = ['isVulgar', 'containsAdjective', 'containsURL', 'containsEmoji', 'containsAbbreviation', 'wordCount']\n",
    "for tag in TwitterParser.tagset:\n",
    "    attributes.append('num_' + tag)\n",
    "    \n",
    "dev_labels = df['classification']\n",
    "dev_labels = [l for l in dev_labels]\n",
    "dev_labels = np.array(dev_labels)\n",
    "\n",
    "# getting the values as a list of lists\n",
    "dev_values = df[attributes].values.tolist()\n",
    "word_embedding_values = df['wordEmbedding'].values.tolist()\n",
    "\n",
    "#Below puts the tweet ID as a feature. Comment this out if you aren't using tweetID\n",
    "###for i,index in enumerate(df.index):\n",
    "###    dev_values[i].append(int(index))\n",
    "\n",
    "\n",
    "\n",
    "for i,d in enumerate(word_embedding_values):\n",
    "    dev_values[i].extend(d)\n",
    "    \n",
    "dev_values = np.array(dev_values, dtype=object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'580319078155468800': ['false', 1.0],\n",
       " '580319184652890113': ['false', 1.0],\n",
       " '580320684305416192': ['unverified', 1.0],\n",
       " '580321156508577792': ['false', 1.0],\n",
       " '580322453928431617': ['false', 1.0],\n",
       " '580323060533764097': ['false', 1.0],\n",
       " '580324027715063808': ['false', 1.0],\n",
       " '580325090367315968': ['unverified', 1.0],\n",
       " '580326222107951104': ['false', 1.0],\n",
       " '580331561398108160': ['false', 1.0],\n",
       " '580332109782466561': ['true', 1.0],\n",
       " '580333763512705025': ['false', 1.0],\n",
       " '580333909008871424': ['true', 1.0],\n",
       " '580339547269144576': ['false', 1.0],\n",
       " '580339825649291264': ['false', 1.0],\n",
       " '580340476949086208': ['false', 1.0],\n",
       " '580348081100734464': ['true', 1.0],\n",
       " '580360165540642816': ['false', 1.0],\n",
       " '580371845997682688': ['false', 1.0],\n",
       " '580882341880446977': ['false', 1.0],\n",
       " '581047170637381632': ['false', 1.0],\n",
       " '581063377226637312': ['true', 1.0],\n",
       " '581293286268129280': ['false', 1.0],\n",
       " '581386094337474560': ['unverified', 1.0],\n",
       " '581473088249958400': ['false', 1.0]}"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import classifiers\n",
    "\n",
    "# note predict_proba() gets probabilities for all 3 labels\n",
    "#... and decision_tree_classifier uses decision_function() instead of predict_proba()... weird sklearn quirk\n",
    "# NOTE: This is where you change the classifier type. Can pick from [naive_bayes, svm_classifier, decision_tree_classifier]\n",
    "predictions, probabilities = classifiers.naive_bayes(dev_values, dev_labels, dev_values)\n",
    "\n",
    "ps = []\n",
    "for i, p in enumerate(predictions):\n",
    "    if p == 0:\n",
    "        ps.append('false')\n",
    "    if p == 1:\n",
    "        ps.append('true')\n",
    "    if p == 2:\n",
    "        ps.append('unverified')\n",
    "    \n",
    "\n",
    "# creates pairings of the prediction and the probability of the prediction\n",
    "pred_probs_pairs = [[ps[i], probabilities[i][predictions[i]]] for i in range(len(predictions))]  \n",
    "\n",
    "#now we make a dictionary of tweetID to the pred_probs_pairs\n",
    "pred_dict = {index:pred_probs_pairs[i] for i,index in enumerate(df.index)}\n",
    "pred_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('output/classifier_output/test.json', 'w') as outfile:\n",
    "    json.dump(pred_dict, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## python3 scorer/score.py semeval2017-task8-dataset/traindev/rumoureval-subtaskB-dev.json output/classifier_output/test.json\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Some comments about performance: WE SHOULD BE SEEING 100% percent veracity accuracy (when using our regular features) naive_bayes = .76 veracity accuracy \n",
    "svm = 1.00 veracity accuracy \n",
    "decision tree = 1.00 veracity accuracy \n",
    "\n",
    "(when using nothing but tweetID)\n",
    "naive_bayes = .44 veracity accuracy\n",
    "svm = .48 veracity accuracy \n",
    "decision tree = 1.00 veracity accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on simple/tr, testing on simple/dev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simply doing all of the transformations we did in the first few cells\n",
    "\n",
    "tr_df = pd.read_pickle('output/simple/train_data_simple.pickle')\n",
    "\n",
    "sys.path.insert(1, \"./feature-extraction/twitter-features\")\n",
    "\n",
    "wordlist = VulgarExtractor.vulgarWords(\"badwords.txt\") \n",
    "dftext = tr_df[['text']]\n",
    "result = dftext.applymap(lambda x: VulgarExtractor.containsVulgar(x,wordlist))\n",
    "tr_df['isVulgar'] = result\n",
    "\n",
    "word_embeddings = [ee.tweetVec(tagged_line) for tagged_line in tr_df['text']]\n",
    "textlist = [txt.replace('\\n','') for txt in tr_df['text'].tolist()]\n",
    "tagged_sents = TwitterParser.tag(textlist)\n",
    "tr_df['POS'] = tagged_sents\n",
    "\n",
    "processed_sents = []\n",
    "for tagged_sent in tr_df['POS']:\n",
    "    processed_words = []\n",
    "    for word, tag in tagged_sent:\n",
    "        if tag == 'U':\n",
    "            processed_words.append('someurl')\n",
    "        elif tag == '@':\n",
    "            processed_words.append('@someuser')\n",
    "        else:\n",
    "            processed_words.append(word)\n",
    "    sent = ' '.join(processed_words)\n",
    "    processed_sents.append(sent)\n",
    "tr_df['text'] = processed_sents\n",
    "\n",
    "word_counts = [TwitterParser.word_count(tagged_line) for tagged_line in tr_df['POS']]\n",
    "pos_count_list = [TwitterParser.pos_counts(tagged_line) for tagged_line in tr_df['POS']]\n",
    "contains_adjs = [TwitterParser.contains_adjectives(tagged_line) for tagged_line in tr_df['POS']]\n",
    "contains_urls = [TwitterParser.contains_url(tagged_line) for tagged_line in tr_df['POS']]\n",
    "contains_emojis = [TwitterParser.contains_emoji(tagged_line) for tagged_line in tr_df['POS']]\n",
    "contains_abbrevs = [TwitterParser.contains_abbreviation(tagged_line) for tagged_line in tr_df['POS']]\n",
    "\n",
    "tr_df['wordCount'] = word_counts\n",
    "tr_df['posCounts'] = pos_count_list\n",
    "tr_df['containsAdjective'] = contains_adjs\n",
    "tr_df['containsURL'] = contains_urls\n",
    "tr_df['containsEmoji'] = contains_emojis\n",
    "tr_df['containsAbbreviation'] = contains_abbrevs\n",
    "tr_df['wordEmbedding'] = word_embeddings\n",
    "\n",
    "\n",
    "for i, tag in enumerate(TwitterParser.tagset):\n",
    "    tag_counts = []\n",
    "    for pos_counts in tr_df['posCounts']:\n",
    "        tag_counts.append(pos_counts[i])\n",
    "    column_name = 'num_' + tag\n",
    "    tr_df[column_name] = tag_counts\n",
    "    normalize(column_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changes \"true\"/\"false\"/\"unverified\" to numeric values, just like the in the early cells\n",
    "\n",
    "tr_df.loc[tr_df.classification == 'true', 'classification'] = 1\n",
    "tr_df.loc[tr_df.classification == 'false', 'classification'] = 0\n",
    "tr_df.loc[tr_df.classification == 'unverified', 'classification'] = 2\n",
    "# getting the labels\n",
    "\n",
    "attributes = ['isVulgar', 'containsAdjective', 'containsURL', 'containsEmoji', 'containsAbbreviation', 'wordCount']\n",
    "for tag in TwitterParser.tagset:\n",
    "    attributes.append('num_' + tag)\n",
    "\n",
    "tr_labels = tr_df['classification']\n",
    "tr_labels = [l for l in tr_labels]\n",
    "tr_labels = np.array(tr_labels)\n",
    "\n",
    "\n",
    "# getting the values as a list of lists\n",
    "tr_values = tr_df[attributes].values.tolist()\n",
    "word_embedding_values = tr_df['wordEmbedding'].values.tolist()\n",
    "\n",
    "\n",
    "#Below puts the tweet ID as a feature. Comment this out if you aren't using tweetID\n",
    "###for i,index in enumerate(df.index):\n",
    "###    dev_values[i].append(int(index))\n",
    "\n",
    "\n",
    "for i,d in enumerate(word_embedding_values):\n",
    "    tr_values[i].extend(d)\n",
    "    \n",
    "tr_values = np.array(tr_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.4650281   1.73304747 -1.68413758]\n",
      " [-0.27548871  0.72663207 -1.20051706]\n",
      " [-0.69281697 -0.02527186 -0.2994328 ]\n",
      " [-0.77958767  0.51392581 -0.43077138]\n",
      " [-0.50464136  0.92828775 -0.76757307]\n",
      " [-0.34137214  1.25425465 -1.32320693]\n",
      " [-0.48393781 -0.13613836 -0.01213038]\n",
      " [-0.88578356  0.22258059  0.07976916]\n",
      " [-0.43339191  0.3529061  -0.88421897]\n",
      " [-0.56767839 -0.50757522 -0.03561522]\n",
      " [-0.31447855 -1.0956812   0.46110576]\n",
      " [-0.54084447  0.51531179 -0.41428251]\n",
      " [-1.52856053  0.31960937  0.5565888 ]\n",
      " [-1.20191896  0.09318688  0.52286172]\n",
      " [-0.59324653  1.38399838 -1.40148087]\n",
      " [-1.21243486  1.66221818 -0.99239366]\n",
      " [-0.51441306  0.34333    -0.31031022]\n",
      " [-1.12509389  0.58825501 -0.39856005]\n",
      " [-1.01500547  0.69434084 -0.49586639]\n",
      " [-1.04353064  0.58651244 -0.23432067]\n",
      " [ 0.06559317 -0.8278979  -0.07115223]\n",
      " [-0.19498093  0.15331865 -0.37893618]\n",
      " [-0.33390785  0.00877709 -0.05238631]\n",
      " [ 0.28989936 -0.9531447  -0.03747179]\n",
      " [-0.85420658  0.61695174 -0.56091992]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'580319078155468800': ['true', 1.7330474699010177],\n",
       " '580319184652890113': ['true', 0.72663206516152756],\n",
       " '580320684305416192': ['true', -0.025271862513169437],\n",
       " '580321156508577792': ['true', 0.51392580944823474],\n",
       " '580322453928431617': ['true', 0.92828775122018814],\n",
       " '580323060533764097': ['true', 1.2542546471604701],\n",
       " '580324027715063808': ['unverified', -0.012130379446322698],\n",
       " '580325090367315968': ['true', 0.22258058557887761],\n",
       " '580326222107951104': ['true', 0.35290610262662037],\n",
       " '580331561398108160': ['unverified', -0.035615220617603596],\n",
       " '580332109782466561': ['unverified', 0.46110575946857468],\n",
       " '580333763512705025': ['true', 0.51531178782070552],\n",
       " '580333909008871424': ['unverified', 0.55658879776773451],\n",
       " '580339547269144576': ['unverified', 0.52286171997697661],\n",
       " '580339825649291264': ['true', 1.3839983827536784],\n",
       " '580340476949086208': ['true', 1.6622181810412315],\n",
       " '580348081100734464': ['true', 0.34332999725530383],\n",
       " '580360165540642816': ['true', 0.5882550052634804],\n",
       " '580371845997682688': ['true', 0.69434083905181976],\n",
       " '580882341880446977': ['true', 0.58651243821604004],\n",
       " '581047170637381632': ['false', 0.06559317071207002],\n",
       " '581063377226637312': ['true', 0.15331864601458228],\n",
       " '581293286268129280': ['true', 0.0087770942459072174],\n",
       " '581386094337474560': ['false', 0.28989935959174246],\n",
       " '581473088249958400': ['true', 0.6169517361649659]}"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions, probabilities = classifiers.svm_classifier(tr_values, tr_labels, dev_values)\n",
    "print(probabilities)\n",
    "ps = []\n",
    "for i, p in enumerate(predictions):\n",
    "    if p == 0:\n",
    "        ps.append('false')\n",
    "    if p == 1:\n",
    "        ps.append('true')\n",
    "    if p == 2:\n",
    "        ps.append('unverified')\n",
    "    \n",
    "\n",
    "# creates pairings of the prediction and the probability of the prediction\n",
    "pred_probs_pairs = [[ps[i], probabilities[i][predictions[i]]] for i in range(len(predictions))]  \n",
    "\n",
    "\n",
    "pred_dict = {index:pred_probs_pairs[i] for i,index in enumerate(df.index)}\n",
    "\n",
    "\n",
    "pred_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('output/classifier_output/tr_test.json', 'w') as outfile:\n",
    "    json.dump(pred_dict, outfile)\n",
    "    \n",
    "#test with:\n",
    "### python3 scorer/score.py semeval2017-task8-dataset/traindev/rumoureval-subtaskB-dev.json output/classifier_output/tr_test.json"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Some comments about performance:\n",
    "    naive_bayes = .32 veracity accuracy \n",
    "    svm = .24 veracity accuracy \n",
    "    decision tree = .36 veracity accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
