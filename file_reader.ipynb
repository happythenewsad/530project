{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating features..\n",
      "\n",
      " 498293668655423488\n",
      "\n",
      " 498486826269548545\n",
      "\n",
      " 500280249629036544\n",
      "\n",
      " 500298588992593920\n",
      "\n",
      " 524923293711998976\n",
      "\n",
      " 524936793633083394\n",
      "\n",
      " 524941720249978880\n",
      "\n",
      " 524948206023880704\n",
      "\n",
      " 524961721744900097\n",
      "\n",
      " 544274544174071809\n",
      "\n",
      " 544294893146091520\n",
      "\n",
      " 544315472075042818\n",
      "\n",
      " 552788945017516032\n",
      "\n",
      " 553480082996879360\n",
      "\n",
      " 553553288625672192\n",
      "\n",
      " 553561170637238272\n",
      "\n",
      " 580352273001410560\n",
      "\n",
      " 581153923987206146\n",
      "\n",
      " 581290271997968384\n",
      "\n",
      " 581359544682614784\n",
      "\n",
      " 758159624122097664\n",
      "\n",
      " 763098277986209792\n",
      "\n",
      " 764927075522260992\n",
      "\n",
      " 767725956706414592\n",
      "\n",
      " 768859780240773121\n",
      "\n",
      " 769988636754505729\n",
      "\n",
      " 774991078265094144\n",
      "\n",
      " 775057555865206784\n",
      "\n",
      " 498293668655423488\n",
      "\n",
      " 498486826269548545\n",
      "\n",
      " 500280249629036544\n",
      "\n",
      " 500298588992593920\n",
      "\n",
      " 524923293711998976\n",
      "\n",
      " 524936793633083394\n",
      "\n",
      " 524941720249978880\n",
      "\n",
      " 524948206023880704\n",
      "\n",
      " 524961721744900097\n",
      "\n",
      " 544274544174071809\n",
      "\n",
      " 544294893146091520\n",
      "\n",
      " 544315472075042818\n",
      "\n",
      " 552788945017516032\n",
      "\n",
      " 553480082996879360\n",
      "\n",
      " 553553288625672192\n",
      "\n",
      " 553561170637238272\n",
      "\n",
      " 580352273001410560\n",
      "\n",
      " 581153923987206146\n",
      "\n",
      " 581290271997968384\n",
      "\n",
      " 581359544682614784\n",
      "\n",
      " 758159624122097664\n",
      "\n",
      " 763098277986209792\n",
      "\n",
      " 764927075522260992\n",
      "\n",
      " 767725956706414592\n",
      "\n",
      " 768859780240773121\n",
      "\n",
      " 769988636754505729\n",
      "\n",
      " 774991078265094144\n",
      "\n",
      " 775057555865206784\n",
      "saving data to output..\n",
      "test code: sample of dev data (simple version) \n",
      "\n",
      "                   classification  \\\n",
      "580319078155468800           true   \n",
      "580319184652890113          false   \n",
      "580320684305416192     unverified   \n",
      "580321156508577792          false   \n",
      "580322453928431617          false   \n",
      "580323060533764097           true   \n",
      "580324027715063808           true   \n",
      "580325090367315968     unverified   \n",
      "580326222107951104          false   \n",
      "580331561398108160          false   \n",
      "\n",
      "                                                         context_path  \\\n",
      "580319078155468800                                                NaN   \n",
      "580319184652890113                                                NaN   \n",
      "580320684305416192                                                NaN   \n",
      "580321156508577792                                                NaN   \n",
      "580322453928431617                                                NaN   \n",
      "580323060533764097                                                NaN   \n",
      "580324027715063808  ./semeval2017-task8-dataset/rumoureval-data/ge...   \n",
      "580325090367315968  ./semeval2017-task8-dataset/rumoureval-data/ge...   \n",
      "580326222107951104  ./semeval2017-task8-dataset/rumoureval-data/ge...   \n",
      "580331561398108160  ./semeval2017-task8-dataset/rumoureval-data/ge...   \n",
      "\n",
      "                   has_context  \\\n",
      "580319078155468800           0   \n",
      "580319184652890113           0   \n",
      "580320684305416192           0   \n",
      "580321156508577792           0   \n",
      "580322453928431617           0   \n",
      "580323060533764097           0   \n",
      "580324027715063808           1   \n",
      "580325090367315968           1   \n",
      "580326222107951104           1   \n",
      "580331561398108160           1   \n",
      "\n",
      "                                                                 text  \\\n",
      "580319078155468800  Germanwings Airbus A320 crashes in French Alps...   \n",
      "580319184652890113  BREAKING: 148 passengers were on board #German...   \n",
      "580320684305416192  Accident aircraft looks to be Germanwings (Air...   \n",
      "580321156508577792  Now hearing 148 passengers + crew on board the...   \n",
      "580322453928431617  German Wings airline tweeting now about report...   \n",
      "580323060533764097  Germanwings passenger plane crashes in France:...   \n",
      "580324027715063808  JUST IN: Germanwings plane crashes in southern...   \n",
      "580325090367315968  Flight #4U9525 initially climbed to 38,000 fee...   \n",
      "580326222107951104  Heart goes out to 148 passengers and crew of G...   \n",
      "580331561398108160  1047 call: DGAC source says pilots called Â«urg...   \n",
      "\n",
      "                         topic  opinion  \n",
      "580319078155468800        true        0  \n",
      "580319184652890113       false        0  \n",
      "580320684305416192  unverified        0  \n",
      "580321156508577792       false        0  \n",
      "580322453928431617       false        0  \n",
      "580323060533764097        true        0  \n",
      "580324027715063808        true        1  \n",
      "580325090367315968  unverified        0  \n",
      "580326222107951104       false        0  \n",
      "580331561398108160       false        0  \n"
     ]
    }
   ],
   "source": [
    "exec(open('file_reader.py').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classification</th>\n",
       "      <th>context_path</th>\n",
       "      <th>has_context</th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "      <th>opinion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>580319078155468800</th>\n",
       "      <td>true</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Germanwings Airbus A320 crashes in French Alps...</td>\n",
       "      <td>true</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580319184652890113</th>\n",
       "      <td>false</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>BREAKING: 148 passengers were on board #German...</td>\n",
       "      <td>false</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580320684305416192</th>\n",
       "      <td>unverified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Accident aircraft looks to be Germanwings (Air...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580321156508577792</th>\n",
       "      <td>false</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Now hearing 148 passengers + crew on board the...</td>\n",
       "      <td>false</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580322453928431617</th>\n",
       "      <td>false</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>German Wings airline tweeting now about report...</td>\n",
       "      <td>false</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   classification context_path has_context  \\\n",
       "580319078155468800           true          NaN           0   \n",
       "580319184652890113          false          NaN           0   \n",
       "580320684305416192     unverified          NaN           0   \n",
       "580321156508577792          false          NaN           0   \n",
       "580322453928431617          false          NaN           0   \n",
       "\n",
       "                                                                 text  \\\n",
       "580319078155468800  Germanwings Airbus A320 crashes in French Alps...   \n",
       "580319184652890113  BREAKING: 148 passengers were on board #German...   \n",
       "580320684305416192  Accident aircraft looks to be Germanwings (Air...   \n",
       "580321156508577792  Now hearing 148 passengers + crew on board the...   \n",
       "580322453928431617  German Wings airline tweeting now about report...   \n",
       "\n",
       "                         topic  opinion  \n",
       "580319078155468800        true        0  \n",
       "580319184652890113       false        0  \n",
       "580320684305416192  unverified        0  \n",
       "580321156508577792       false        0  \n",
       "580322453928431617       false        0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, \"./feature-extraction/twitter-features\")\n",
    "from VulgarExtractor import VulgarExtractor\n",
    "from EmbedExtractor import EmbedExtractor\n",
    "ee = EmbedExtractor()\n",
    "print(\"hi!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist = VulgarExtractor.vulgarWords(\"badwords.txt\") \n",
    "dftext = df[['text']]\n",
    "result = dftext.applymap(lambda x: VulgarExtractor.containsVulgar(x,wordlist))\n",
    "df['isVulgar'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d4aab9f63f29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mTwitterParser\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTwitterParser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtextlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtxt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtxt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtagged_sents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTwitterParser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtextlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtagged_sents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'POS'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtagged_sents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "from TwitterParser import TwitterParser\n",
    "textlist = [txt.replace('\\n','') for txt in df['text'].tolist()]\n",
    "tagged_sents = TwitterParser.tag(textlist)\n",
    "print(len(tagged_sents))\n",
    "df['POS'] = tagged_sents\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-7cc826acb356>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mword_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mTwitterParser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtagged_line\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtagged_line\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'POS'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpos_count_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mTwitterParser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtagged_line\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtagged_line\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'POS'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcontains_adjs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mTwitterParser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains_adjectives\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtagged_line\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtagged_line\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'POS'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "word_counts = [TwitterParser.word_count(tagged_line) for tagged_line in df['POS']]\n",
    "pos_count_list = [TwitterParser.pos_counts(tagged_line) for tagged_line in df['POS']]\n",
    "contains_adjs = [TwitterParser.contains_adjectives(tagged_line) for tagged_line in df['POS']]\n",
    "contains_urls = [TwitterParser.contains_url(tagged_line) for tagged_line in df['POS']]\n",
    "contains_emojis = [TwitterParser.contains_emoji(tagged_line) for tagged_line in df['POS']]\n",
    "contains_abbrevs = [TwitterParser.contains_abbreviation(tagged_line) for tagged_line in df['POS']]\n",
    "word_embeddings = [ee.tweetVec(tagged_line) for tagged_line in df['POS']]\n",
    "\n",
    "with open('feature-extraction/twitter-features/word_embedding_vectors_dev.pickle','rb') as we_pickle:\n",
    "    word_em = pickle.load(we_pickle)\n",
    "    \n",
    "df['wordCount'] = word_counts\n",
    "df['posCounts'] = pos_count_list\n",
    "df['containsAdjective'] = contains_adjs\n",
    "df['containsURL'] = contains_urls\n",
    "df['containsEmoji'] = contains_emojis\n",
    "df['containsAbbreviation'] = contains_abbrevs\n",
    "df['wordEmbedding']=word_embeddings\n",
    "print(df['wordEmbedding'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, tag in enumerate(TwitterParser.tagset):\n",
    "    tag_counts = []\n",
    "    for pos_counts in df['posCounts']:\n",
    "        tag_counts.append(pos_counts[i])\n",
    "    column_name = 'num_' + tag\n",
    "    df[column_name] = tag_counts\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, False, False],\n",
       "       [False,  True, False, False, False],\n",
       "       [False, False, False, False, False],\n",
       "       [False,  True, False, False, False],\n",
       "       [False,  True, False, False, False],\n",
       "       [False, False, False, False, False],\n",
       "       [False,  True, False, False, False],\n",
       "       [False,  True, False, False,  True],\n",
       "       [False, False, False, False, False],\n",
       "       [False, False, False, False,  True],\n",
       "       [ True,  True, False, False, False],\n",
       "       [False,  True, False, False, False],\n",
       "       [False, False, False, False,  True],\n",
       "       [False,  True, False, False, False],\n",
       "       [False,  True, False, False, False],\n",
       "       [False,  True, False, False, False],\n",
       "       [False,  True, False, False, False],\n",
       "       [False, False, False, False, False],\n",
       "       [False, False, False, False, False],\n",
       "       [False,  True, False, False, False],\n",
       "       [False,  True, False, False, False],\n",
       "       [False, False, False, False, False],\n",
       "       [False,  True, False, False, False],\n",
       "       [False,  True, False, False, False],\n",
       "       [False, False, False, False,  True]], dtype=bool)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.loc[df.classification == 'true', 'classification'] = 1\n",
    "df.loc[df.classification == 'false', 'classification'] = 0\n",
    "df.loc[df.classification == 'unverified', 'classification'] = 2\n",
    "\n",
    "\n",
    "attributes = []\n",
    "# getting the labels\n",
    "# You have to comment this out if you want only tweet ID to be in the features. \n",
    "# Note that by doing this, you will screw up the simple/tr,simple/dev test located after this\n",
    "attributes = ['isVulgar', 'containsAdjective', 'containsURL', 'containsEmoji', 'containsAbbreviation']\n",
    "\n",
    "dev_labels = df['classification']\n",
    "dev_labels = [l for l in labels]\n",
    "dev_labels = np.array(labels)\n",
    "\n",
    "# getting the values as a list of lists\n",
    "dev_values = df[attributes].values.tolist()\n",
    "\n",
    "\n",
    "#Below puts the tweet ID as a feature. Comment this out if you aren't using tweetID\n",
    "###for i,index in enumerate(df.index):\n",
    "###    dev_values[i].append(int(index))\n",
    "\n",
    "\n",
    "dev_values = np.array(dev_values)\n",
    "dev_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import classifiers\n",
    "\n",
    "# note predict_proba() gets probabilities for all 3 labels\n",
    "#... and decision_tree_classifier uses decision_function() instead of predict_proba()... weird sklearn quirk\n",
    "# NOTE: This is where you change the classifier type. Can pick from [naive_bayes, svm_classifier, decision_tree_classifier]\n",
    "predictions, probabilities = classifiers.naive_bayes(dev_values, dev_labels, dev_values)\n",
    "\n",
    "ps = []\n",
    "for i, p in enumerate(predictions):\n",
    "    if p == 0:\n",
    "        ps.append('false')\n",
    "    if p == 1:\n",
    "        ps.append('true')\n",
    "    if p == 2:\n",
    "        ps.append('unverified')\n",
    "    \n",
    "\n",
    "# creates pairings of the prediction and the probability of the prediction\n",
    "pred_probs_pairs = [[ps[i], probabilities[i][predictions[i]]] for i in range(len(predictions))]  \n",
    "\n",
    "#now we make a dictionary of tweetID to the pred_probs_pairs\n",
    "pred_dict = {index:pred_probs_pairs[i] for i,index in enumerate(df.index)}\n",
    "pred_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output/classifier_output/test.json', 'w') as outfile:\n",
    "    json.dump(pred_dict, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## python3 scorer/score.py semeval2017-task8-dataset/traindev/rumoureval-subtaskB-dev.json output/classifier_output/test.json\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Some comments about performance:\n",
    "WE SHOULD BE SEEING 100% percent veracity accuracy\n",
    "\n",
    "(when using our regular features)\n",
    "naive_bayes = .52 veracity accuracy\n",
    "svm = .6 veracity accuracy\n",
    "decision tree = .64 veracity accuracy\n",
    "\n",
    "\n",
    "(when using nothing but tweetID)\n",
    "naive_bayes = .44 veracity accuracy\n",
    "svm = .48 veracity accuracy\n",
    "decision tree = 1.00 veracity accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on simple/tr, testing on simple/dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'VulgarExtractor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-f3bd28009b08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtr_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'output/simple/train_data_simple.pickle'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mwordlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVulgarExtractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvulgarWords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"badwords.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mdftext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtr_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdftext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mVulgarExtractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontainsVulgar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwordlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'VulgarExtractor' is not defined"
     ]
    }
   ],
   "source": [
    "# Simply doing all of the transformations we did in the first few cells\n",
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "sys.path.insert(0, '/feature-extraction/twitter-features/')\n",
    "\n",
    "tr_df = pd.read_pickle('output/simple/train_data_simple.pickle')\n",
    "\n",
    "wordlist = VulgarExtractor.vulgarWords(\"badwords.txt\") \n",
    "dftext = tr_df[['text']]\n",
    "result = dftext.applymap(lambda x: VulgarExtractor.containsVulgar(x,wordlist))\n",
    "tr_df['isVulgar'] = result\n",
    "\n",
    "sys.path.insert(1, \"./feature-extraction/twitter-features\")\n",
    "textlist = [txt.replace('\\n','') for txt in tr_df['text'].tolist()]\n",
    "tagged_sents = TwitterParser.tag(textlist)\n",
    "tr_df['POS'] = tagged_sents\n",
    "\n",
    "word_counts = [TwitterParser.word_count(tagged_line) for tagged_line in tr_df['POS']]\n",
    "pos_count_list = [TwitterParser.pos_counts(tagged_line) for tagged_line in tr_df['POS']]\n",
    "contains_adjs = [TwitterParser.contains_adjectives(tagged_line) for tagged_line in tr_df['POS']]\n",
    "contains_urls = [TwitterParser.contains_url(tagged_line) for tagged_line in tr_df['POS']]\n",
    "contains_emojis = [TwitterParser.contains_emoji(tagged_line) for tagged_line in tr_df['POS']]\n",
    "contains_abbrevs = [TwitterParser.contains_abbreviation(tagged_line) for tagged_line in tr_df['POS']]\n",
    "\n",
    "tr_df['wordCount'] = word_counts\n",
    "tr_df['posCounts'] = pos_count_list\n",
    "tr_df['containsAdjective'] = contains_adjs\n",
    "tr_df['containsURL'] = contains_urls\n",
    "tr_df['containsEmoji'] = contains_emojis\n",
    "tr_df['containsAbbreviation'] = contains_abbrevs\n",
    "print(tr_df['wordCount'])\n",
    "for i, tag in enumerate(TwitterParser.tagset):\n",
    "    tag_counts = []\n",
    "    for pos_counts in tr_df['posCounts']:\n",
    "        tag_counts.append(pos_counts[i])\n",
    "    column_name = 'num_' + tag\n",
    "    tr_df[column_name] = tag_counts\n",
    "\n",
    "tr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-8908afa0a262>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtr_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtr_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'classification'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mtr_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtr_labels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtr_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# Changes \"true\"/\"false\"/\"unverified\" to numeric values, just like the in the early cells\n",
    "\n",
    "tr_df.loc[tr_df.classification == 'true', 'classification'] = 1\n",
    "tr_df.loc[tr_df.classification == 'false', 'classification'] = 0\n",
    "tr_df.loc[tr_df.classification == 'unverified', 'classification'] = 2\n",
    "# getting the labels\n",
    "\n",
    "attributes = ['isVulgar', 'containsAdjective', 'containsURL', 'containsEmoji', 'containsAbbreviation']\n",
    "\n",
    "\n",
    "tr_labels = tr_df['classification']\n",
    "tr_labels = [l for l in tr_labels]\n",
    "tr_labels = np.array(tr_labels)\n",
    "\n",
    "\n",
    "# getting the values as a list of lists\n",
    "tr_values = tr_df[attributes].values.tolist()\n",
    "tr_values = np.array(tr_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classifiers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e05e396a1821>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifiers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_tree_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobabilities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'classifiers' is not defined"
     ]
    }
   ],
   "source": [
    "predictions, probabilities = classifiers.decision_tree_classifier(tr_values, tr_labels, dev_values)\n",
    "print(probabilities)\n",
    "ps = []\n",
    "for i, p in enumerate(predictions):\n",
    "    if p == 0:\n",
    "        ps.append('false')\n",
    "    if p == 1:\n",
    "        ps.append('true')\n",
    "    if p == 2:\n",
    "        ps.append('unverified')\n",
    "    \n",
    "\n",
    "# creates pairings of the prediction and the probability of the prediction\n",
    "pred_probs_pairs = [[ps[i], probabilities[i][predictions[i]]] for i in range(len(predictions))]  \n",
    "\n",
    "\n",
    "pred_dict = {index:pred_probs_pairs[i] for i,index in enumerate(df.index)}\n",
    "\n",
    "\n",
    "pred_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'output/classifier_output/tr_test.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-da60f9afee45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'output/classifier_output/tr_test.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#test with:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m### python3 scorer/score.py semeval2017-task8-dataset/traindev/rumoureval-subtaskB-dev.json output/classifier_output/tr_test.json\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'output/classifier_output/tr_test.json'"
     ]
    }
   ],
   "source": [
    "with open('output/classifier_output/tr_test.json', 'w') as outfile:\n",
    "    json.dump(pred_dict, outfile)\n",
    "    \n",
    "#test with:\n",
    "### python3 scorer/score.py semeval2017-task8-dataset/traindev/rumoureval-subtaskB-dev.json output/classifier_output/tr_test.json"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Some comments about performance:\n",
    "\n",
    "\n",
    "naive_bayes = .16 veracity accuracy\n",
    "svm = .24 veracity accuracy\n",
    "decision tree = .24 veracity accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
