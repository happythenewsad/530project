{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating features..\n",
      "\n",
      " 498293668655423488\n",
      "\n",
      " 498486826269548545\n",
      "\n",
      " 500280249629036544\n",
      "\n",
      " 500298588992593920\n",
      "\n",
      " 524923293711998976\n",
      "\n",
      " 524936793633083394\n",
      "\n",
      " 524941720249978880\n",
      "\n",
      " 524948206023880704\n",
      "\n",
      " 524961721744900097\n",
      "\n",
      " 544274544174071809\n",
      "\n",
      " 544294893146091520\n",
      "\n",
      " 544315472075042818\n",
      "\n",
      " 552788945017516032\n",
      "\n",
      " 553480082996879360\n",
      "\n",
      " 553553288625672192\n",
      "\n",
      " 553561170637238272\n",
      "\n",
      " 580352273001410560\n",
      "\n",
      " 581153923987206146\n",
      "\n",
      " 581290271997968384\n",
      "\n",
      " 581359544682614784\n",
      "\n",
      " 758159624122097664\n",
      "\n",
      " 763098277986209792\n",
      "\n",
      " 764927075522260992\n",
      "\n",
      " 767725956706414592\n",
      "\n",
      " 768859780240773121\n",
      "\n",
      " 769988636754505729\n",
      "\n",
      " 774991078265094144\n",
      "\n",
      " 775057555865206784\n",
      "\n",
      " 498293668655423488\n",
      "\n",
      " 498486826269548545\n",
      "\n",
      " 500280249629036544\n",
      "\n",
      " 500298588992593920\n",
      "\n",
      " 524923293711998976\n",
      "\n",
      " 524936793633083394\n",
      "\n",
      " 524941720249978880\n",
      "\n",
      " 524948206023880704\n",
      "\n",
      " 524961721744900097\n",
      "\n",
      " 544274544174071809\n",
      "\n",
      " 544294893146091520\n",
      "\n",
      " 544315472075042818\n",
      "\n",
      " 552788945017516032\n",
      "\n",
      " 553480082996879360\n",
      "\n",
      " 553553288625672192\n",
      "\n",
      " 553561170637238272\n",
      "\n",
      " 580352273001410560\n",
      "\n",
      " 581153923987206146\n",
      "\n",
      " 581290271997968384\n",
      "\n",
      " 581359544682614784\n",
      "\n",
      " 758159624122097664\n",
      "\n",
      " 763098277986209792\n",
      "\n",
      " 764927075522260992\n",
      "\n",
      " 767725956706414592\n",
      "\n",
      " 768859780240773121\n",
      "\n",
      " 769988636754505729\n",
      "\n",
      " 774991078265094144\n",
      "\n",
      " 775057555865206784\n",
      "saving data to output..\n",
      "test code: sample of dev data (simple version) \n",
      "\n",
      "                   classification  \\\n",
      "580319078155468800           true   \n",
      "580319184652890113          false   \n",
      "580320684305416192     unverified   \n",
      "580321156508577792          false   \n",
      "580322453928431617          false   \n",
      "580323060533764097           true   \n",
      "580324027715063808           true   \n",
      "580325090367315968     unverified   \n",
      "580326222107951104          false   \n",
      "580331561398108160          false   \n",
      "\n",
      "                                                         context_path  \\\n",
      "580319078155468800  ./semeval2017-task8-dataset/rumoureval-data/ge...   \n",
      "580319184652890113  ./semeval2017-task8-dataset/rumoureval-data/ge...   \n",
      "580320684305416192  ./semeval2017-task8-dataset/rumoureval-data/ge...   \n",
      "580321156508577792  ./semeval2017-task8-dataset/rumoureval-data/ge...   \n",
      "580322453928431617  ./semeval2017-task8-dataset/rumoureval-data/ge...   \n",
      "580323060533764097  ./semeval2017-task8-dataset/rumoureval-data/ge...   \n",
      "580324027715063808  ./semeval2017-task8-dataset/rumoureval-data/ge...   \n",
      "580325090367315968  ./semeval2017-task8-dataset/rumoureval-data/ge...   \n",
      "580326222107951104  ./semeval2017-task8-dataset/rumoureval-data/ge...   \n",
      "580331561398108160  ./semeval2017-task8-dataset/rumoureval-data/ge...   \n",
      "\n",
      "                   has_context  \\\n",
      "580319078155468800           1   \n",
      "580319184652890113           1   \n",
      "580320684305416192           1   \n",
      "580321156508577792           1   \n",
      "580322453928431617           1   \n",
      "580323060533764097           1   \n",
      "580324027715063808           1   \n",
      "580325090367315968           1   \n",
      "580326222107951104           1   \n",
      "580331561398108160           1   \n",
      "\n",
      "                                                                 text  \\\n",
      "580319078155468800  Germanwings Airbus A320 crashes in French Alps...   \n",
      "580319184652890113  BREAKING: 148 passengers were on board #German...   \n",
      "580320684305416192  Accident aircraft looks to be Germanwings (Air...   \n",
      "580321156508577792  Now hearing 148 passengers + crew on board the...   \n",
      "580322453928431617  German Wings airline tweeting now about report...   \n",
      "580323060533764097  Germanwings passenger plane crashes in France:...   \n",
      "580324027715063808  JUST IN: Germanwings plane crashes in southern...   \n",
      "580325090367315968  Flight #4U9525 initially climbed to 38,000 fee...   \n",
      "580326222107951104  Heart goes out to 148 passengers and crew of G...   \n",
      "580331561398108160  1047 call: DGAC source says pilots called Â«urg...   \n",
      "\n",
      "                         topic  opinion  \n",
      "580319078155468800        true        0  \n",
      "580319184652890113       false        0  \n",
      "580320684305416192  unverified        0  \n",
      "580321156508577792       false        0  \n",
      "580322453928431617       false        0  \n",
      "580323060533764097        true        0  \n",
      "580324027715063808        true        1  \n",
      "580325090367315968  unverified        0  \n",
      "580326222107951104       false        0  \n",
      "580331561398108160       false        0  \n"
     ]
    }
   ],
   "source": [
    "exec(open('file_reader.py').read())\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, \"./feature-extraction/twitter-features\")\n",
    "from EmbedExtractor import EmbedExtractor\n",
    "from VulgarExtractor import VulgarExtractor\n",
    "\n",
    "ee = EmbedExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist = VulgarExtractor.vulgarWords(\"badwords.txt\") \n",
    "dftext = df[['text']]\n",
    "result = dftext.applymap(lambda x: VulgarExtractor.containsVulgar(x,wordlist))\n",
    "df['isVulgar'] = result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classification</th>\n",
       "      <th>context_path</th>\n",
       "      <th>has_context</th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "      <th>opinion</th>\n",
       "      <th>isVulgar</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>580319078155468800</th>\n",
       "      <td>true</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Germanwings Airbus A320 crashes in French Alps...</td>\n",
       "      <td>true</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>[(Germanwings, ^), (Airbus, ^), (A320, ^), (cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580319184652890113</th>\n",
       "      <td>false</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>BREAKING: 148 passengers were on board #German...</td>\n",
       "      <td>false</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>[(BREAKING, N), (:, ,), (148, $), (passengers,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580320684305416192</th>\n",
       "      <td>unverified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Accident aircraft looks to be Germanwings (Air...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>[(Accident, N), (aircraft, N), (looks, V), (to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580321156508577792</th>\n",
       "      <td>false</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Now hearing 148 passengers + crew on board the...</td>\n",
       "      <td>false</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>[(Now, R), (hearing, V), (148, $), (passengers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580322453928431617</th>\n",
       "      <td>false</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>German Wings airline tweeting now about report...</td>\n",
       "      <td>false</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>[(German, A), (Wings, N), (airline, N), (tweet...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   classification context_path has_context  \\\n",
       "580319078155468800           true          NaN           0   \n",
       "580319184652890113          false          NaN           0   \n",
       "580320684305416192     unverified          NaN           0   \n",
       "580321156508577792          false          NaN           0   \n",
       "580322453928431617          false          NaN           0   \n",
       "\n",
       "                                                                 text  \\\n",
       "580319078155468800  Germanwings Airbus A320 crashes in French Alps...   \n",
       "580319184652890113  BREAKING: 148 passengers were on board #German...   \n",
       "580320684305416192  Accident aircraft looks to be Germanwings (Air...   \n",
       "580321156508577792  Now hearing 148 passengers + crew on board the...   \n",
       "580322453928431617  German Wings airline tweeting now about report...   \n",
       "\n",
       "                         topic  opinion  isVulgar  \\\n",
       "580319078155468800        true        0     False   \n",
       "580319184652890113       false        0     False   \n",
       "580320684305416192  unverified        0     False   \n",
       "580321156508577792       false        0     False   \n",
       "580322453928431617       false        0     False   \n",
       "\n",
       "                                                                  POS  \n",
       "580319078155468800  [(Germanwings, ^), (Airbus, ^), (A320, ^), (cr...  \n",
       "580319184652890113  [(BREAKING, N), (:, ,), (148, $), (passengers,...  \n",
       "580320684305416192  [(Accident, N), (aircraft, N), (looks, V), (to...  \n",
       "580321156508577792  [(Now, R), (hearing, V), (148, $), (passengers...  \n",
       "580322453928431617  [(German, A), (Wings, N), (airline, N), (tweet...  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#word embeddings must be generated before POS\n",
    "word_embeddings =\n",
    "\n",
    "from TwitterParser import TwitterParser\n",
    "textlist = [txt.replace('\\n','') for txt in df['text'].tolist()]\n",
    "tagged_sents = TwitterParser.tag(textlist)\n",
    "df['POS'] = tagged_sents\n",
    "#df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "processed_sents = []\n",
    "for tagged_sent in df['POS']:\n",
    "    processed_words = []\n",
    "    for word, tag in tagged_sent:\n",
    "        if tag == 'U':\n",
    "            processed_words.append('someurl')\n",
    "        elif tag == '@':\n",
    "            processed_words.append('@someuser')\n",
    "        else:\n",
    "            processed_words.append(word)\n",
    "    sent = ' '.join(processed_words)\n",
    "    processed_sents.append(sent)\n",
    "df['text'] = processed_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "580319078155468800    False\n",
       "580319184652890113    False\n",
       "580320684305416192    False\n",
       "580321156508577792    False\n",
       "580322453928431617    False\n",
       "580323060533764097    False\n",
       "580324027715063808    False\n",
       "580325090367315968    False\n",
       "580326222107951104    False\n",
       "580331561398108160    False\n",
       "580332109782466561    False\n",
       "580333763512705025    False\n",
       "580333909008871424    False\n",
       "580339547269144576    False\n",
       "580339825649291264    False\n",
       "580340476949086208    False\n",
       "580348081100734464    False\n",
       "580360165540642816    False\n",
       "580371845997682688    False\n",
       "580882341880446977    False\n",
       "581047170637381632    False\n",
       "581063377226637312    False\n",
       "581293286268129280    False\n",
       "581386094337474560    False\n",
       "581473088249958400    False\n",
       "Name: containsEmoji, dtype: bool"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(column_name):\n",
    "    std = df[column_name].std()\n",
    "    norm_col = df[column_name].apply(lambda x: x - std)\n",
    "    df[column_name] = norm_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classification</th>\n",
       "      <th>context_path</th>\n",
       "      <th>has_context</th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "      <th>opinion</th>\n",
       "      <th>isVulgar</th>\n",
       "      <th>POS</th>\n",
       "      <th>wordCount</th>\n",
       "      <th>posCounts</th>\n",
       "      <th>containsAdjective</th>\n",
       "      <th>containsURL</th>\n",
       "      <th>containsEmoji</th>\n",
       "      <th>containsAbbreviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>580319078155468800</th>\n",
       "      <td>true</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Germanwings Airbus A320 crashes in French Alps...</td>\n",
       "      <td>true</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>[(Germanwings, ^), (Airbus, ^), (A320, ^), (cr...</td>\n",
       "      <td>4.555903</td>\n",
       "      <td>[0, 0, 0, 6, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580319184652890113</th>\n",
       "      <td>false</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>BREAKING : 148 passengers were on board #Germa...</td>\n",
       "      <td>false</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>[(BREAKING, N), (:, ,), (148, $), (passengers,...</td>\n",
       "      <td>11.555903</td>\n",
       "      <td>[3, 0, 0, 4, 0, 0, 0, 3, 1, 0, 0, 2, 2, 0, 0, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580320684305416192</th>\n",
       "      <td>unverified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Accident aircraft looks to be Germanwings ( Ai...</td>\n",
       "      <td>unverified</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>[(Accident, N), (aircraft, N), (looks, V), (to...</td>\n",
       "      <td>11.555903</td>\n",
       "      <td>[5, 0, 0, 4, 0, 0, 0, 2, 0, 0, 0, 0, 2, 1, 0, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580321156508577792</th>\n",
       "      <td>false</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Now hearing 148 passengers + crew on board the...</td>\n",
       "      <td>false</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>[(Now, R), (hearing, V), (148, $), (passengers...</td>\n",
       "      <td>13.555903</td>\n",
       "      <td>[4, 0, 0, 2, 0, 0, 0, 3, 1, 1, 0, 1, 3, 1, 0, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580322453928431617</th>\n",
       "      <td>false</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>German Wings airline tweeting now about report...</td>\n",
       "      <td>false</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>[(German, A), (Wings, N), (airline, N), (tweet...</td>\n",
       "      <td>12.555903</td>\n",
       "      <td>[5, 0, 0, 2, 0, 0, 0, 2, 1, 1, 0, 0, 5, 0, 0, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   classification context_path has_context  \\\n",
       "580319078155468800           true          NaN           0   \n",
       "580319184652890113          false          NaN           0   \n",
       "580320684305416192     unverified          NaN           0   \n",
       "580321156508577792          false          NaN           0   \n",
       "580322453928431617          false          NaN           0   \n",
       "\n",
       "                                                                 text  \\\n",
       "580319078155468800  Germanwings Airbus A320 crashes in French Alps...   \n",
       "580319184652890113  BREAKING : 148 passengers were on board #Germa...   \n",
       "580320684305416192  Accident aircraft looks to be Germanwings ( Ai...   \n",
       "580321156508577792  Now hearing 148 passengers + crew on board the...   \n",
       "580322453928431617  German Wings airline tweeting now about report...   \n",
       "\n",
       "                         topic  opinion  isVulgar  \\\n",
       "580319078155468800        true        0     False   \n",
       "580319184652890113       false        0     False   \n",
       "580320684305416192  unverified        0     False   \n",
       "580321156508577792       false        0     False   \n",
       "580322453928431617       false        0     False   \n",
       "\n",
       "                                                                  POS  \\\n",
       "580319078155468800  [(Germanwings, ^), (Airbus, ^), (A320, ^), (cr...   \n",
       "580319184652890113  [(BREAKING, N), (:, ,), (148, $), (passengers,...   \n",
       "580320684305416192  [(Accident, N), (aircraft, N), (looks, V), (to...   \n",
       "580321156508577792  [(Now, R), (hearing, V), (148, $), (passengers...   \n",
       "580322453928431617  [(German, A), (Wings, N), (airline, N), (tweet...   \n",
       "\n",
       "                    wordCount  \\\n",
       "580319078155468800   4.555903   \n",
       "580319184652890113  11.555903   \n",
       "580320684305416192  11.555903   \n",
       "580321156508577792  13.555903   \n",
       "580322453928431617  12.555903   \n",
       "\n",
       "                                                            posCounts  \\\n",
       "580319078155468800  [0, 0, 0, 6, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, ...   \n",
       "580319184652890113  [3, 0, 0, 4, 0, 0, 0, 3, 1, 0, 0, 2, 2, 0, 0, ...   \n",
       "580320684305416192  [5, 0, 0, 4, 0, 0, 0, 2, 0, 0, 0, 0, 2, 1, 0, ...   \n",
       "580321156508577792  [4, 0, 0, 2, 0, 0, 0, 3, 1, 1, 0, 1, 3, 1, 0, ...   \n",
       "580322453928431617  [5, 0, 0, 2, 0, 0, 0, 2, 1, 1, 0, 0, 5, 0, 0, ...   \n",
       "\n",
       "                    containsAdjective  containsURL  containsEmoji  \\\n",
       "580319078155468800              False         True          False   \n",
       "580319184652890113               True         True          False   \n",
       "580320684305416192              False         True          False   \n",
       "580321156508577792               True        False          False   \n",
       "580322453928431617               True         True          False   \n",
       "\n",
       "                    containsAbbreviation  \n",
       "580319078155468800                 False  \n",
       "580319184652890113                 False  \n",
       "580320684305416192                 False  \n",
       "580321156508577792                 False  \n",
       "580322453928431617                 False  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import TwitterParser features\n",
    "word_counts = [TwitterParser.word_count(tagged_line) for tagged_line in df['POS']]\n",
    "pos_count_list = [TwitterParser.pos_counts(tagged_line) for tagged_line in df['POS']]\n",
    "contains_adjs = [TwitterParser.contains_adjectives(tagged_line) for tagged_line in df['POS']]\n",
    "contains_urls = [TwitterParser.contains_url(tagged_line) for tagged_line in df['POS']]\n",
    "contains_emojis = [TwitterParser.contains_emoji(tagged_line) for tagged_line in df['POS']]\n",
    "contains_abbrevs = [TwitterParser.contains_abbreviation(tagged_line) for tagged_line in df['POS']]\n",
    "\n",
    "# get word count and normalize\n",
    "df['wordCount'] = word_counts\n",
    "normalize('wordCount')\n",
    "\n",
    "# get an indexed list of pos tag counts\n",
    "df['posCounts'] = pos_count_list\n",
    "\n",
    "# get binary features\n",
    "df['containsAdjective'] = contains_adjs\n",
    "df['containsURL'] = contains_urls\n",
    "df['containsEmoji'] = contains_emojis\n",
    "df['containsAbbreviation'] = contains_abbrevs\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, tag in enumerate(TwitterParser.tagset):\n",
    "    tag_counts = []\n",
    "    for pos_counts in df['posCounts']:\n",
    "        tag_counts.append(pos_counts[i])\n",
    "    column_name = 'num_' + tag\n",
    "    df[column_name] = tag_counts\n",
    "    normalize(column_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   4.55590279e+00,\n",
       "         -2.03469899e+00,  -4.08248290e-01,   0.00000000e+00,\n",
       "          4.09649446e+00,   0.00000000e+00,  -2.00000000e-01,\n",
       "          0.00000000e+00,  -1.15993937e-02,  -7.78888096e-01,\n",
       "         -5.00000000e-01,   0.00000000e+00,  -9.00000000e-01,\n",
       "          4.75751551e-01,  -4.58257569e-01,  -3.31662479e-01,\n",
       "          0.00000000e+00,   0.00000000e+00,  -5.68624070e-01,\n",
       "         -4.08248290e-01,  -4.00000000e-01,   4.02784238e-01,\n",
       "          0.00000000e+00,  -8.40634681e-01,  -2.13541565e+00,\n",
       "         -2.00000000e-01],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   1.15559028e+01,\n",
       "          9.65301005e-01,  -4.08248290e-01,   0.00000000e+00,\n",
       "          2.09649446e+00,   0.00000000e+00,  -2.00000000e-01,\n",
       "          0.00000000e+00,   1.98840061e+00,   2.21111904e-01,\n",
       "         -5.00000000e-01,   0.00000000e+00,   1.10000000e+00,\n",
       "          4.75751551e-01,  -4.58257569e-01,  -3.31662479e-01,\n",
       "          0.00000000e+00,   0.00000000e+00,   4.31375930e-01,\n",
       "         -4.08248290e-01,  -4.00000000e-01,   4.02784238e-01,\n",
       "          0.00000000e+00,   1.59365319e-01,  -1.13541565e+00,\n",
       "         -2.00000000e-01],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   1.15559028e+01,\n",
       "          2.96530101e+00,  -4.08248290e-01,   0.00000000e+00,\n",
       "          2.09649446e+00,   0.00000000e+00,  -2.00000000e-01,\n",
       "          0.00000000e+00,   9.88400606e-01,  -7.78888096e-01,\n",
       "         -5.00000000e-01,   0.00000000e+00,  -9.00000000e-01,\n",
       "          4.75751551e-01,   5.41742431e-01,  -3.31662479e-01,\n",
       "          0.00000000e+00,   0.00000000e+00,   4.31375930e-01,\n",
       "         -4.08248290e-01,  -4.00000000e-01,   4.02784238e-01,\n",
       "          0.00000000e+00,   1.15936532e+00,   1.86458435e+00,\n",
       "         -2.00000000e-01],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   1.35559028e+01,\n",
       "          1.96530101e+00,  -4.08248290e-01,   0.00000000e+00,\n",
       "          9.64944620e-02,   0.00000000e+00,  -2.00000000e-01,\n",
       "          0.00000000e+00,   1.98840061e+00,   2.21111904e-01,\n",
       "          5.00000000e-01,   0.00000000e+00,   1.00000000e-01,\n",
       "          1.47575155e+00,   5.41742431e-01,  -3.31662479e-01,\n",
       "          0.00000000e+00,   0.00000000e+00,   4.31375930e-01,\n",
       "          5.91751710e-01,  -4.00000000e-01,  -5.97215762e-01,\n",
       "          0.00000000e+00,   1.15936532e+00,  -1.35415650e-01,\n",
       "         -2.00000000e-01],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   1.25559028e+01,\n",
       "          2.96530101e+00,  -4.08248290e-01,   0.00000000e+00,\n",
       "          9.64944620e-02,   0.00000000e+00,  -2.00000000e-01,\n",
       "          0.00000000e+00,   9.88400606e-01,   2.21111904e-01,\n",
       "          5.00000000e-01,   0.00000000e+00,  -9.00000000e-01,\n",
       "          3.47575155e+00,  -4.58257569e-01,  -3.31662479e-01,\n",
       "          0.00000000e+00,   0.00000000e+00,  -5.68624070e-01,\n",
       "          5.91751710e-01,  -4.00000000e-01,   4.02784238e-01,\n",
       "          0.00000000e+00,   1.59365319e-01,  -1.13541565e+00,\n",
       "         -2.00000000e-01],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   1.55590279e+00,\n",
       "         -1.03469899e+00,  -4.08248290e-01,   0.00000000e+00,\n",
       "          1.09649446e+00,   0.00000000e+00,  -2.00000000e-01,\n",
       "          0.00000000e+00,  -1.15993937e-02,  -7.78888096e-01,\n",
       "         -5.00000000e-01,   0.00000000e+00,  -9.00000000e-01,\n",
       "         -5.24248449e-01,  -4.58257569e-01,  -3.31662479e-01,\n",
       "          0.00000000e+00,   0.00000000e+00,  -5.68624070e-01,\n",
       "         -4.08248290e-01,  -4.00000000e-01,   4.02784238e-01,\n",
       "          0.00000000e+00,  -8.40634681e-01,  -1.13541565e+00,\n",
       "         -2.00000000e-01],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   8.55590279e+00,\n",
       "         -1.03469899e+00,  -4.08248290e-01,   0.00000000e+00,\n",
       "          9.64944620e-02,   0.00000000e+00,  -2.00000000e-01,\n",
       "          0.00000000e+00,   9.88400606e-01,   1.22111190e+00,\n",
       "          5.00000000e-01,   0.00000000e+00,  -9.00000000e-01,\n",
       "          1.47575155e+00,  -4.58257569e-01,   6.68337521e-01,\n",
       "          0.00000000e+00,   0.00000000e+00,  -5.68624070e-01,\n",
       "         -4.08248290e-01,  -4.00000000e-01,   4.02784238e-01,\n",
       "          0.00000000e+00,   1.59365319e-01,  -1.35415650e-01,\n",
       "         -2.00000000e-01],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   1.35559028e+01,\n",
       "          1.96530101e+00,   5.91751710e-01,   0.00000000e+00,\n",
       "         -1.90350554e+00,   0.00000000e+00,  -2.00000000e-01,\n",
       "          0.00000000e+00,   1.98840061e+00,   2.21111904e-01,\n",
       "          5.00000000e-01,   0.00000000e+00,  -9.00000000e-01,\n",
       "          3.47575155e+00,   5.41742431e-01,  -3.31662479e-01,\n",
       "          0.00000000e+00,   0.00000000e+00,   4.31375930e-01,\n",
       "         -4.08248290e-01,  -4.00000000e-01,   4.02784238e-01,\n",
       "          0.00000000e+00,   1.15936532e+00,  -1.13541565e+00,\n",
       "         -2.00000000e-01],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   1.55559028e+01,\n",
       "          9.65301005e-01,  -4.08248290e-01,   0.00000000e+00,\n",
       "          5.09649446e+00,   0.00000000e+00,  -2.00000000e-01,\n",
       "          0.00000000e+00,   1.98840061e+00,  -7.78888096e-01,\n",
       "         -5.00000000e-01,   0.00000000e+00,  -9.00000000e-01,\n",
       "          2.47575155e+00,   5.41742431e-01,   6.68337521e-01,\n",
       "          0.00000000e+00,   0.00000000e+00,  -5.68624070e-01,\n",
       "         -4.08248290e-01,  -4.00000000e-01,   4.02784238e-01,\n",
       "          0.00000000e+00,   1.59365319e-01,  -1.13541565e+00,\n",
       "         -2.00000000e-01],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   1.00000000e+00,   1.55559028e+01,\n",
       "          7.96530101e+00,  -4.08248290e-01,   0.00000000e+00,\n",
       "         -9.03505538e-01,   0.00000000e+00,  -2.00000000e-01,\n",
       "          0.00000000e+00,   1.98840061e+00,  -7.78888096e-01,\n",
       "         -5.00000000e-01,   0.00000000e+00,   1.00000000e-01,\n",
       "          4.75751551e-01,   5.41742431e-01,  -3.31662479e-01,\n",
       "          0.00000000e+00,   0.00000000e+00,   4.31375930e-01,\n",
       "         -4.08248290e-01,  -4.00000000e-01,  -5.97215762e-01,\n",
       "          0.00000000e+00,   1.15936532e+00,   7.86458435e+00,\n",
       "          8.00000000e-01],\n",
       "       [  1.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   2.15559028e+01,\n",
       "          2.96530101e+00,   5.91751710e-01,   0.00000000e+00,\n",
       "          9.64944620e-02,   0.00000000e+00,   8.00000000e-01,\n",
       "          0.00000000e+00,   2.98840061e+00,   2.21111904e-01,\n",
       "          5.00000000e-01,   0.00000000e+00,   1.00000000e-01,\n",
       "          5.47575155e+00,  -4.58257569e-01,   6.68337521e-01,\n",
       "          0.00000000e+00,   0.00000000e+00,   4.31375930e-01,\n",
       "         -4.08248290e-01,  -4.00000000e-01,  -5.97215762e-01,\n",
       "          0.00000000e+00,   1.15936532e+00,   1.86458435e+00,\n",
       "         -2.00000000e-01],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   9.55590279e+00,\n",
       "          9.65301005e-01,  -4.08248290e-01,   0.00000000e+00,\n",
       "          3.09649446e+00,   0.00000000e+00,  -2.00000000e-01,\n",
       "          0.00000000e+00,  -1.15993937e-02,   2.21111904e-01,\n",
       "         -5.00000000e-01,   0.00000000e+00,  -9.00000000e-01,\n",
       "         -5.24248449e-01,   5.41742431e-01,  -3.31662479e-01,\n",
       "          0.00000000e+00,   0.00000000e+00,   4.31375930e-01,\n",
       "         -4.08248290e-01,  -4.00000000e-01,   4.02784238e-01,\n",
       "          0.00000000e+00,   1.15936532e+00,  -1.13541565e+00,\n",
       "         -2.00000000e-01],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   1.25559028e+01,\n",
       "          2.96530101e+00,   5.91751710e-01,   0.00000000e+00,\n",
       "          3.09649446e+00,   0.00000000e+00,  -2.00000000e-01,\n",
       "          0.00000000e+00,   9.88400606e-01,  -7.78888096e-01,\n",
       "         -5.00000000e-01,   0.00000000e+00,   1.10000000e+00,\n",
       "          4.75751551e-01,  -4.58257569e-01,  -3.31662479e-01,\n",
       "          0.00000000e+00,   0.00000000e+00,  -5.68624070e-01,\n",
       "         -4.08248290e-01,  -4.00000000e-01,   4.02784238e-01,\n",
       "          0.00000000e+00,  -8.40634681e-01,  -1.13541565e+00,\n",
       "         -2.00000000e-01],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   1.45559028e+01,\n",
       "          2.96530101e+00,  -4.08248290e-01,   0.00000000e+00,\n",
       "          9.64944620e-02,   0.00000000e+00,  -2.00000000e-01,\n",
       "          0.00000000e+00,   1.98840061e+00,   1.22111190e+00,\n",
       "         -5.00000000e-01,   0.00000000e+00,   1.10000000e+00,\n",
       "          2.47575155e+00,  -4.58257569e-01,  -3.31662479e-01,\n",
       "          0.00000000e+00,   0.00000000e+00,  -5.68624070e-01,\n",
       "         -4.08248290e-01,  -4.00000000e-01,   4.02784238e-01,\n",
       "          0.00000000e+00,   1.59365319e-01,   2.86458435e+00,\n",
       "         -2.00000000e-01],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   4.55590279e+00,\n",
       "         -3.46989949e-02,  -4.08248290e-01,   0.00000000e+00,\n",
       "          9.64944620e-02,   0.00000000e+00,  -2.00000000e-01,\n",
       "          0.00000000e+00,  -1.15993937e-02,   2.21111904e-01,\n",
       "         -5.00000000e-01,   0.00000000e+00,  -9.00000000e-01,\n",
       "          4.75751551e-01,  -4.58257569e-01,  -3.31662479e-01,\n",
       "          0.00000000e+00,   0.00000000e+00,   4.31375930e-01,\n",
       "         -4.08248290e-01,  -4.00000000e-01,   1.40278424e+00,\n",
       "          0.00000000e+00,   1.59365319e-01,  -2.13541565e+00,\n",
       "         -2.00000000e-01],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   3.55590279e+00,\n",
       "         -3.46989949e-02,  -4.08248290e-01,   0.00000000e+00,\n",
       "         -9.03505538e-01,   0.00000000e+00,  -2.00000000e-01,\n",
       "          0.00000000e+00,   9.88400606e-01,   2.21111904e-01,\n",
       "         -5.00000000e-01,   0.00000000e+00,  -9.00000000e-01,\n",
       "         -5.24248449e-01,  -4.58257569e-01,  -3.31662479e-01,\n",
       "          0.00000000e+00,   0.00000000e+00,  -5.68624070e-01,\n",
       "         -4.08248290e-01,  -4.00000000e-01,   4.02784238e-01,\n",
       "          0.00000000e+00,   1.59365319e-01,  -1.13541565e+00,\n",
       "         -2.00000000e-01],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   1.25559028e+01,\n",
       "          1.96530101e+00,   5.91751710e-01,   0.00000000e+00,\n",
       "          9.64944620e-02,   0.00000000e+00,  -2.00000000e-01,\n",
       "          0.00000000e+00,   9.88400606e-01,   2.21111904e-01,\n",
       "          5.00000000e-01,   0.00000000e+00,  -9.00000000e-01,\n",
       "          1.47575155e+00,   5.41742431e-01,  -3.31662479e-01,\n",
       "          0.00000000e+00,   0.00000000e+00,   1.43137593e+00,\n",
       "         -4.08248290e-01,  -4.00000000e-01,   4.02784238e-01,\n",
       "          0.00000000e+00,   1.15936532e+00,  -1.35415650e-01,\n",
       "         -2.00000000e-01],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   1.25559028e+01,\n",
       "          4.96530101e+00,  -4.08248290e-01,   0.00000000e+00,\n",
       "          3.09649446e+00,   0.00000000e+00,  -2.00000000e-01,\n",
       "          0.00000000e+00,   9.88400606e-01,  -7.78888096e-01,\n",
       "          5.00000000e-01,   0.00000000e+00,   1.00000000e-01,\n",
       "         -5.24248449e-01,  -4.58257569e-01,  -3.31662479e-01,\n",
       "          0.00000000e+00,   0.00000000e+00,   4.31375930e-01,\n",
       "          5.91751710e-01,  -4.00000000e-01,  -5.97215762e-01,\n",
       "          0.00000000e+00,  -8.40634681e-01,   2.86458435e+00,\n",
       "         -2.00000000e-01],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   9.55590279e+00,\n",
       "          9.65301005e-01,  -4.08248290e-01,   0.00000000e+00,\n",
       "          1.09649446e+00,   0.00000000e+00,  -2.00000000e-01,\n",
       "          0.00000000e+00,   1.98840061e+00,  -7.78888096e-01,\n",
       "         -5.00000000e-01,   0.00000000e+00,  -9.00000000e-01,\n",
       "          1.47575155e+00,  -4.58257569e-01,  -3.31662479e-01,\n",
       "          0.00000000e+00,   0.00000000e+00,   4.31375930e-01,\n",
       "         -4.08248290e-01,  -4.00000000e-01,  -5.97215762e-01,\n",
       "          0.00000000e+00,   1.15936532e+00,  -1.35415650e-01,\n",
       "         -2.00000000e-01],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   5.55590279e+00,\n",
       "          2.96530101e+00,  -4.08248290e-01,   0.00000000e+00,\n",
       "         -1.90350554e+00,   0.00000000e+00,  -2.00000000e-01,\n",
       "          0.00000000e+00,  -1.15993937e-02,   2.21111904e-01,\n",
       "         -5.00000000e-01,   0.00000000e+00,  -9.00000000e-01,\n",
       "          1.47575155e+00,  -4.58257569e-01,  -3.31662479e-01,\n",
       "          0.00000000e+00,   0.00000000e+00,   4.31375930e-01,\n",
       "         -4.08248290e-01,  -4.00000000e-01,   1.40278424e+00,\n",
       "          0.00000000e+00,  -8.40634681e-01,  -1.13541565e+00,\n",
       "         -2.00000000e-01],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   1.15559028e+01,\n",
       "          1.96530101e+00,  -4.08248290e-01,   0.00000000e+00,\n",
       "          2.09649446e+00,   0.00000000e+00,  -2.00000000e-01,\n",
       "          0.00000000e+00,   9.88400606e-01,   2.21111904e-01,\n",
       "          5.00000000e-01,   0.00000000e+00,   1.00000000e-01,\n",
       "          1.47575155e+00,  -4.58257569e-01,  -3.31662479e-01,\n",
       "          0.00000000e+00,   0.00000000e+00,   4.31375930e-01,\n",
       "         -4.08248290e-01,  -4.00000000e-01,  -5.97215762e-01,\n",
       "          0.00000000e+00,  -8.40634681e-01,  -1.35415650e-01,\n",
       "         -2.00000000e-01],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   1.05559028e+01,\n",
       "          2.96530101e+00,   5.91751710e-01,   0.00000000e+00,\n",
       "          1.09649446e+00,   0.00000000e+00,  -2.00000000e-01,\n",
       "          0.00000000e+00,  -1.15993937e-02,  -7.78888096e-01,\n",
       "         -5.00000000e-01,   0.00000000e+00,   2.10000000e+00,\n",
       "          4.75751551e-01,  -4.58257569e-01,  -3.31662479e-01,\n",
       "          0.00000000e+00,   0.00000000e+00,   4.31375930e-01,\n",
       "         -4.08248290e-01,  -4.00000000e-01,  -5.97215762e-01,\n",
       "          0.00000000e+00,  -8.40634681e-01,  -1.35415650e-01,\n",
       "         -2.00000000e-01],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   1.35559028e+01,\n",
       "          9.65301005e-01,  -4.08248290e-01,   0.00000000e+00,\n",
       "          2.09649446e+00,   0.00000000e+00,  -2.00000000e-01,\n",
       "          0.00000000e+00,   3.98840061e+00,   2.21111904e-01,\n",
       "          5.00000000e-01,   0.00000000e+00,   1.10000000e+00,\n",
       "          4.75751551e-01,  -4.58257569e-01,  -3.31662479e-01,\n",
       "          0.00000000e+00,   0.00000000e+00,  -5.68624070e-01,\n",
       "         -4.08248290e-01,  -4.00000000e-01,  -5.97215762e-01,\n",
       "          0.00000000e+00,  -8.40634681e-01,   8.64584350e-01,\n",
       "         -2.00000000e-01],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   7.55590279e+00,\n",
       "          9.65301005e-01,  -4.08248290e-01,   0.00000000e+00,\n",
       "         -9.03505538e-01,   0.00000000e+00,  -2.00000000e-01,\n",
       "          0.00000000e+00,   9.88400606e-01,   2.22111190e+00,\n",
       "          5.00000000e-01,   0.00000000e+00,   1.00000000e-01,\n",
       "         -1.52424845e+00,  -4.58257569e-01,  -3.31662479e-01,\n",
       "          0.00000000e+00,   0.00000000e+00,   4.31375930e-01,\n",
       "          5.91751710e-01,   1.60000000e+00,   4.02784238e-01,\n",
       "          0.00000000e+00,   1.59365319e-01,  -1.35415650e-01,\n",
       "         -2.00000000e-01],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   1.05559028e+01,\n",
       "          1.96530101e+00,  -4.08248290e-01,   0.00000000e+00,\n",
       "          4.09649446e+00,   0.00000000e+00,  -2.00000000e-01,\n",
       "          0.00000000e+00,   9.88400606e-01,  -7.78888096e-01,\n",
       "         -5.00000000e-01,   0.00000000e+00,  -9.00000000e-01,\n",
       "          1.47575155e+00,  -4.58257569e-01,  -3.31662479e-01,\n",
       "          0.00000000e+00,   0.00000000e+00,  -5.68624070e-01,\n",
       "          5.91751710e-01,  -4.00000000e-01,   4.02784238e-01,\n",
       "          0.00000000e+00,  -8.40634681e-01,   1.86458435e+00,\n",
       "         -2.00000000e-01]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.classification == 'true', 'classification'] = 1\n",
    "df.loc[df.classification == 'false', 'classification'] = 0\n",
    "df.loc[df.classification == 'unverified', 'classification'] = 2\n",
    "\n",
    "\n",
    "attributes = []\n",
    "# getting the labels\n",
    "# You have to comment this out if you want only tweet ID to be in the features. \n",
    "# Note that by doing this, you will screw up the simple/tr,simple/dev test located after this\n",
    "\n",
    "\n",
    "attributes = ['isVulgar', 'containsAdjective', 'containsURL', 'containsEmoji', 'containsAbbreviation', 'wordCount']\n",
    "for tag in TwitterParser.tagset:\n",
    "    attributes.append('num_' + tag)\n",
    "    \n",
    "dev_labels = df['classification']\n",
    "dev_labels = [l for l in dev_labels]\n",
    "dev_labels = np.array(dev_labels)\n",
    "\n",
    "# getting the values as a list of lists\n",
    "dev_values = df[attributes].values.tolist()\n",
    "\n",
    "\n",
    "#Below puts the tweet ID as a feature. Comment this out if you aren't using tweetID\n",
    "###for i,index in enumerate(df.index):\n",
    "###    dev_values[i].append(int(index))\n",
    "\n",
    "\n",
    "dev_values = np.array(dev_values)\n",
    "dev_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'580319078155468800': ['true', 0.95746996011498731],\n",
       " '580319184652890113': ['false', 0.91892254283776831],\n",
       " '580320684305416192': ['unverified', 0.32277503893861303],\n",
       " '580321156508577792': ['false', 0.94151205147246642],\n",
       " '580322453928431617': ['false', 0.7848577090372737],\n",
       " '580323060533764097': ['true', 0.86898159178682643],\n",
       " '580324027715063808': ['true', 0.48270640684194371],\n",
       " '580325090367315968': ['unverified', 0.48202942159192241],\n",
       " '580326222107951104': ['false', 0.49484034035034097],\n",
       " '580331561398108160': ['false', 0.83898892614722409],\n",
       " '580332109782466561': ['true', 1.485489419334052],\n",
       " '580333763512705025': ['false', 0.84365031964414494],\n",
       " '580333909008871424': ['true', 0.53162708465152719],\n",
       " '580339547269144576': ['false', 0.74389842527095906],\n",
       " '580339825649291264': ['false', 0.066571660462573179],\n",
       " '580340476949086208': ['false', 0.58048486709082114],\n",
       " '580348081100734464': ['true', 0.29082590644303236],\n",
       " '580360165540642816': ['false', 0.54334329295454309],\n",
       " '580371845997682688': ['true', 0.40089964458786725],\n",
       " '580882341880446977': ['true', 0.36490244818579248],\n",
       " '581047170637381632': ['true', 0.93036685418910148],\n",
       " '581063377226637312': ['true', 2.6914166083252433],\n",
       " '581293286268129280': ['false', 1.2781767101240546],\n",
       " '581386094337474560': ['unverified', 0.78161631440330859],\n",
       " '581473088249958400': ['false', 1.1008076643256655]}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import classifiers\n",
    "\n",
    "# note predict_proba() gets probabilities for all 3 labels\n",
    "#... and decision_tree_classifier uses decision_function() instead of predict_proba()... weird sklearn quirk\n",
    "# NOTE: This is where you change the classifier type. Can pick from [naive_bayes, svm_classifier, decision_tree_classifier]\n",
    "predictions, probabilities = classifiers.svm_classifier(dev_values, dev_labels, dev_values)\n",
    "\n",
    "ps = []\n",
    "for i, p in enumerate(predictions):\n",
    "    if p == 0:\n",
    "        ps.append('false')\n",
    "    if p == 1:\n",
    "        ps.append('true')\n",
    "    if p == 2:\n",
    "        ps.append('unverified')\n",
    "    \n",
    "\n",
    "# creates pairings of the prediction and the probability of the prediction\n",
    "pred_probs_pairs = [[ps[i], probabilities[i][predictions[i]]] for i in range(len(predictions))]  \n",
    "\n",
    "#now we make a dictionary of tweetID to the pred_probs_pairs\n",
    "pred_dict = {index:pred_probs_pairs[i] for i,index in enumerate(df.index)}\n",
    "pred_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('output/classifier_output/test.json', 'w') as outfile:\n",
    "    json.dump(pred_dict, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## python3 scorer/score.py semeval2017-task8-dataset/traindev/rumoureval-subtaskB-dev.json output/classifier_output/test.json\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Some comments about performance: WE SHOULD BE SEEING 100% percent veracity accuracy (when using our regular features) naive_bayes = .84 veracity accuracy \n",
    "svm = .96 veracity accuracy \n",
    "decision tree = 1.00 veracity accuracy \n",
    "\n",
    "(when using nothing but tweetID)\n",
    "naive_bayes = .44 veracity accuracy\n",
    "svm = .48 veracity accuracy \n",
    "decision tree = 1.00 veracity accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on simple/tr, testing on simple/dev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classification</th>\n",
       "      <th>context_path</th>\n",
       "      <th>has_context</th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "      <th>isVulgar</th>\n",
       "      <th>POS</th>\n",
       "      <th>wordCount</th>\n",
       "      <th>posCounts</th>\n",
       "      <th>containsAdjective</th>\n",
       "      <th>...</th>\n",
       "      <th>num_X</th>\n",
       "      <th>num_Y</th>\n",
       "      <th>num_#</th>\n",
       "      <th>num_@</th>\n",
       "      <th>num_~</th>\n",
       "      <th>num_U</th>\n",
       "      <th>num_E</th>\n",
       "      <th>num_$</th>\n",
       "      <th>num_,</th>\n",
       "      <th>num_G</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>498280126254428160</th>\n",
       "      <td>unverified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Mike Brown was staying with his grandmother fo...</td>\n",
       "      <td>ferguson</td>\n",
       "      <td>False</td>\n",
       "      <td>[(Mike, ^), (Brown, ^), (was, V), (staying, V)...</td>\n",
       "      <td>15</td>\n",
       "      <td>[3, 1, 0, 2, 0, 0, 0, 3, 0, 0, 0, 3, 3, 0, 0, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498430783699554305</th>\n",
       "      <td>true</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Witness : Police allegedly stopped Mike Brown ...</td>\n",
       "      <td>ferguson</td>\n",
       "      <td>False</td>\n",
       "      <td>[(Witness, N), (:, ,), (Police, N), (allegedly...</td>\n",
       "      <td>14</td>\n",
       "      <td>[3, 1, 0, 2, 0, 0, 0, 3, 0, 1, 0, 0, 4, 0, 0, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499366666300846081</th>\n",
       "      <td>unverified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Line of police cars with high beams on greets ...</td>\n",
       "      <td>ferguson</td>\n",
       "      <td>False</td>\n",
       "      <td>[(Line, N), (of, P), (police, N), (cars, N), (...</td>\n",
       "      <td>20</td>\n",
       "      <td>[6, 0, 0, 1, 0, 1, 0, 5, 1, 0, 0, 1, 4, 0, 1, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499368931367608320</th>\n",
       "      <td>unverified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Currently the #FoxNews website has zero , repe...</td>\n",
       "      <td>ferguson</td>\n",
       "      <td>False</td>\n",
       "      <td>[(Currently, R), (the, D), (#FoxNews, ^), (web...</td>\n",
       "      <td>20</td>\n",
       "      <td>[7, 0, 0, 3, 0, 0, 0, 1, 1, 2, 0, 2, 3, 0, 0, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499456140044824576</th>\n",
       "      <td>unverified</td>\n",
       "      <td>./semeval2017-task8-dataset/rumoureval-data/fe...</td>\n",
       "      <td>1</td>\n",
       "      <td>St. Louis Co Police tell me ofcr shot a man wh...</td>\n",
       "      <td>ferguson</td>\n",
       "      <td>False</td>\n",
       "      <td>[(St., ^), (Louis, ^), (Co, ^), (Police, ^), (...</td>\n",
       "      <td>26</td>\n",
       "      <td>[5, 3, 0, 6, 0, 0, 0, 2, 2, 0, 0, 1, 5, 1, 0, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   classification  \\\n",
       "498280126254428160     unverified   \n",
       "498430783699554305           true   \n",
       "499366666300846081     unverified   \n",
       "499368931367608320     unverified   \n",
       "499456140044824576     unverified   \n",
       "\n",
       "                                                         context_path  \\\n",
       "498280126254428160                                                NaN   \n",
       "498430783699554305                                                NaN   \n",
       "499366666300846081                                                NaN   \n",
       "499368931367608320                                                NaN   \n",
       "499456140044824576  ./semeval2017-task8-dataset/rumoureval-data/fe...   \n",
       "\n",
       "                   has_context  \\\n",
       "498280126254428160           0   \n",
       "498430783699554305           0   \n",
       "499366666300846081           0   \n",
       "499368931367608320           0   \n",
       "499456140044824576           1   \n",
       "\n",
       "                                                                 text  \\\n",
       "498280126254428160  Mike Brown was staying with his grandmother fo...   \n",
       "498430783699554305  Witness : Police allegedly stopped Mike Brown ...   \n",
       "499366666300846081  Line of police cars with high beams on greets ...   \n",
       "499368931367608320  Currently the #FoxNews website has zero , repe...   \n",
       "499456140044824576  St. Louis Co Police tell me ofcr shot a man wh...   \n",
       "\n",
       "                       topic  isVulgar  \\\n",
       "498280126254428160  ferguson     False   \n",
       "498430783699554305  ferguson     False   \n",
       "499366666300846081  ferguson     False   \n",
       "499368931367608320  ferguson     False   \n",
       "499456140044824576  ferguson     False   \n",
       "\n",
       "                                                                  POS  \\\n",
       "498280126254428160  [(Mike, ^), (Brown, ^), (was, V), (staying, V)...   \n",
       "498430783699554305  [(Witness, N), (:, ,), (Police, N), (allegedly...   \n",
       "499366666300846081  [(Line, N), (of, P), (police, N), (cars, N), (...   \n",
       "499368931367608320  [(Currently, R), (the, D), (#FoxNews, ^), (web...   \n",
       "499456140044824576  [(St., ^), (Louis, ^), (Co, ^), (Police, ^), (...   \n",
       "\n",
       "                    wordCount  \\\n",
       "498280126254428160         15   \n",
       "498430783699554305         14   \n",
       "499366666300846081         20   \n",
       "499368931367608320         20   \n",
       "499456140044824576         26   \n",
       "\n",
       "                                                            posCounts  \\\n",
       "498280126254428160  [3, 1, 0, 2, 0, 0, 0, 3, 0, 0, 0, 3, 3, 0, 0, ...   \n",
       "498430783699554305  [3, 1, 0, 2, 0, 0, 0, 3, 0, 1, 0, 0, 4, 0, 0, ...   \n",
       "499366666300846081  [6, 0, 0, 1, 0, 1, 0, 5, 1, 0, 0, 1, 4, 0, 1, ...   \n",
       "499368931367608320  [7, 0, 0, 3, 0, 0, 0, 1, 1, 2, 0, 2, 3, 0, 0, ...   \n",
       "499456140044824576  [5, 3, 0, 6, 0, 0, 0, 2, 2, 0, 0, 1, 5, 1, 0, ...   \n",
       "\n",
       "                    containsAdjective  ...    num_X  num_Y  num_#  num_@  \\\n",
       "498280126254428160              False  ...        0      0      1      0   \n",
       "498430783699554305              False  ...        0      0      1      0   \n",
       "499366666300846081               True  ...        0      0      0      0   \n",
       "499368931367608320               True  ...        0      0      0      0   \n",
       "499456140044824576               True  ...        0      0      1      0   \n",
       "\n",
       "                    num_~  num_U  num_E  num_$  num_,  num_G  \n",
       "498280126254428160      0      0      0      0      2      0  \n",
       "498430783699554305      0      1      0      0      2      0  \n",
       "499366666300846081      0      1      0      0      3      0  \n",
       "499368931367608320      0      0      0      1      4      0  \n",
       "499456140044824576      0      0      0      1      1      0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simply doing all of the transformations we did in the first few cells\n",
    "\n",
    "tr_df = pd.read_pickle('output/simple/train_data_simple.pickle')\n",
    "\n",
    "sys.path.insert(1, \"./feature-extraction/twitter-features\")\n",
    "\n",
    "wordlist = VulgarExtractor.vulgarWords(\"badwords.txt\") \n",
    "dftext = tr_df[['text']]\n",
    "result = dftext.applymap(lambda x: VulgarExtractor.containsVulgar(x,wordlist))\n",
    "tr_df['isVulgar'] = result\n",
    "\n",
    "textlist = [txt.replace('\\n','') for txt in tr_df['text'].tolist()]\n",
    "tagged_sents = TwitterParser.tag(textlist)\n",
    "tr_df['POS'] = tagged_sents\n",
    "\n",
    "processed_sents = []\n",
    "for tagged_sent in tr_df['POS']:\n",
    "    processed_words = []\n",
    "    for word, tag in tagged_sent:\n",
    "        if tag == 'U':\n",
    "            processed_words.append('someurl')\n",
    "        elif tag == '@':\n",
    "            processed_words.append('@someuser')\n",
    "        else:\n",
    "            processed_words.append(word)\n",
    "    sent = ' '.join(processed_words)\n",
    "    processed_sents.append(sent)\n",
    "tr_df['text'] = processed_sents\n",
    "\n",
    "word_counts = [TwitterParser.word_count(tagged_line) for tagged_line in tr_df['POS']]\n",
    "pos_count_list = [TwitterParser.pos_counts(tagged_line) for tagged_line in tr_df['POS']]\n",
    "contains_adjs = [TwitterParser.contains_adjectives(tagged_line) for tagged_line in tr_df['POS']]\n",
    "contains_urls = [TwitterParser.contains_url(tagged_line) for tagged_line in tr_df['POS']]\n",
    "contains_emojis = [TwitterParser.contains_emoji(tagged_line) for tagged_line in tr_df['POS']]\n",
    "contains_abbrevs = [TwitterParser.contains_abbreviation(tagged_line) for tagged_line in tr_df['POS']]\n",
    "\n",
    "tr_df['wordCount'] = word_counts\n",
    "tr_df['posCounts'] = pos_count_list\n",
    "tr_df['containsAdjective'] = contains_adjs\n",
    "tr_df['containsURL'] = contains_urls\n",
    "tr_df['containsEmoji'] = contains_emojis\n",
    "tr_df['containsAbbreviation'] = contains_abbrevs\n",
    "\n",
    "for i, tag in enumerate(TwitterParser.tagset):\n",
    "    tag_counts = []\n",
    "    for pos_counts in tr_df['posCounts']:\n",
    "        tag_counts.append(pos_counts[i])\n",
    "    column_name = 'num_' + tag\n",
    "    tr_df[column_name] = tag_counts\n",
    "\n",
    "tr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Changes \"true\"/\"false\"/\"unverified\" to numeric values, just like the in the early cells\n",
    "\n",
    "tr_df.loc[tr_df.classification == 'true', 'classification'] = 1\n",
    "tr_df.loc[tr_df.classification == 'false', 'classification'] = 0\n",
    "tr_df.loc[tr_df.classification == 'unverified', 'classification'] = 2\n",
    "# getting the labels\n",
    "\n",
    "attributes = ['isVulgar', 'containsAdjective', 'containsURL', 'containsEmoji', 'containsAbbreviation', 'wordCount']\n",
    "for tag in TwitterParser.tagset:\n",
    "    attributes.append('num_' + tag)\n",
    "\n",
    "tr_labels = tr_df['classification']\n",
    "tr_labels = [l for l in tr_labels]\n",
    "tr_labels = np.array(tr_labels)\n",
    "\n",
    "\n",
    "# getting the values as a list of lists\n",
    "tr_values = tr_df[attributes].values.tolist()\n",
    "tr_values = np.array(tr_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 1.  0.  0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'580319078155468800': ['false', 1.0],\n",
       " '580319184652890113': ['false', 1.0],\n",
       " '580320684305416192': ['true', 1.0],\n",
       " '580321156508577792': ['true', 1.0],\n",
       " '580322453928431617': ['unverified', 1.0],\n",
       " '580323060533764097': ['false', 1.0],\n",
       " '580324027715063808': ['false', 1.0],\n",
       " '580325090367315968': ['true', 1.0],\n",
       " '580326222107951104': ['true', 1.0],\n",
       " '580331561398108160': ['unverified', 1.0],\n",
       " '580332109782466561': ['unverified', 1.0],\n",
       " '580333763512705025': ['true', 1.0],\n",
       " '580333909008871424': ['true', 1.0],\n",
       " '580339547269144576': ['unverified', 1.0],\n",
       " '580339825649291264': ['false', 1.0],\n",
       " '580340476949086208': ['false', 1.0],\n",
       " '580348081100734464': ['unverified', 1.0],\n",
       " '580360165540642816': ['unverified', 1.0],\n",
       " '580371845997682688': ['false', 1.0],\n",
       " '580882341880446977': ['true', 1.0],\n",
       " '581047170637381632': ['false', 1.0],\n",
       " '581063377226637312': ['unverified', 1.0],\n",
       " '581293286268129280': ['false', 1.0],\n",
       " '581386094337474560': ['unverified', 1.0],\n",
       " '581473088249958400': ['false', 1.0]}"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions, probabilities = classifiers.decision_tree_classifier(tr_values, tr_labels, dev_values)\n",
    "print(probabilities)\n",
    "ps = []\n",
    "for i, p in enumerate(predictions):\n",
    "    if p == 0:\n",
    "        ps.append('false')\n",
    "    if p == 1:\n",
    "        ps.append('true')\n",
    "    if p == 2:\n",
    "        ps.append('unverified')\n",
    "    \n",
    "\n",
    "# creates pairings of the prediction and the probability of the prediction\n",
    "pred_probs_pairs = [[ps[i], probabilities[i][predictions[i]]] for i in range(len(predictions))]  \n",
    "\n",
    "\n",
    "pred_dict = {index:pred_probs_pairs[i] for i,index in enumerate(df.index)}\n",
    "\n",
    "\n",
    "pred_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('output/classifier_output/tr_test.json', 'w') as outfile:\n",
    "    json.dump(pred_dict, outfile)\n",
    "    \n",
    "#test with:\n",
    "### python3 scorer/score.py semeval2017-task8-dataset/traindev/rumoureval-subtaskB-dev.json output/classifier_output/tr_test.json"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Some comments about performance:\n",
    "    naive_bayes = .36 veracity accuracy \n",
    "    svm = .48 veracity accuracy \n",
    "    decision tree = .32 veracity accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
