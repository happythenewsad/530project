{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from FileReader import FileReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving data to output..\n"
     ]
    }
   ],
   "source": [
    "classInstance = FileReader\n",
    "df_list = classInstance.get_dataframe() #IMPORTANT:  saves a pickle to output/simple or output/full. \n",
    "\n",
    "#The pickle is the same as df.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTANT NOTE:\n",
    "\n",
    "Word embeddings are expressed as pickle files.\n",
    "Reading of tweet data is converted to a Pandas Dataframe format and then finally into a pickle file, located output/simple or output/full.\n",
    "\n",
    "It is important that you first execute file_reader.py and *then* this notebook, run_tests.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(1, \"./feature-extraction/embed-extractor\")\n",
    "from EmbedExtractor import EmbedExtractor\n",
    "sys.path.insert(1, \"./feature-extraction/vulgar-extractor\")\n",
    "from VulgarExtractor import VulgarExtractor\n",
    "sys.path.insert(1, \"./feature-extraction/twitter-parser\")\n",
    "from TwitterParser import TwitterParser\n",
    "sys.path.insert(1, \"./feature-extraction/opinion-extractor/\")\n",
    "from OpinionExtractor import OpinionExtractor\n",
    "from sklearn import decomposition\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "import classifiers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oh\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "18\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "18\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "18\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "18\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "18\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "OH!\n",
      "OH!\n",
      "OH!\n",
      "OH!\n",
      "OH!\n"
     ]
    }
   ],
   "source": [
    "# Run this cell to generate the pre-PCA and post-PCA word embeddings\n",
    "print(\"oh\")\n",
    "def chunkIt(seq, num):\n",
    "    print(len(seq))\n",
    "    avg = len(seq) / float(num)\n",
    "    out = []\n",
    "    last = 0.0\n",
    "    zeros = [0]*int(avg)\n",
    "\n",
    "    while last < len(seq):\n",
    "        subVector = seq[int(last):int(last + avg)]\n",
    "        if zeros==subVector and last>4700:\n",
    "            break\n",
    "        out.append(subVector)\n",
    "        last += avg\n",
    "    return out\n",
    "\n",
    "####UNCOMMENT THIS TO RUN THE EE#####\n",
    "# ee = EmbedExtractor()\n",
    "# tweet2vec = {}\n",
    "    \n",
    "# for d in [\"train\",\"dev\",\"test\"]:\n",
    "# \twith open('./output/full/'+d+'_data_full.json', 'r') as f:\n",
    "# \t    jstr = f.read()\n",
    "\n",
    "# \tj = json.loads(jstr)\n",
    "\n",
    "# \tfor key in j:\n",
    "# \t\ttweet=j[key]['text']\n",
    "# \t\ttweet2vec[key]=ee.tweetVec(tweet)\n",
    "# pickleFile=\"feature-extraction/embed-extractor/word_embedding_vectors.pickle\"\n",
    "# pickle.dump(tweet2vec,open(pickleFile,\"wb\"))\n",
    "# ##########################################\n",
    "\n",
    "\n",
    "word_embeddings_pca = {}\n",
    "pickleFile=\"feature-extraction/embed-extractor/word_embedding_vectors.pickle\"\n",
    "word_embeddings = pd.read_pickle(pickleFile)\n",
    "\n",
    "word_embeddings_chunked = {}\n",
    "for word in word_embeddings:\n",
    "    word_embeddings_chunked[word]=chunkIt(word_embeddings[word],30)\n",
    "for word in word_embeddings_chunked:\n",
    "    pca = decomposition.PCA(n_components=24)\n",
    "    x = np.array(word_embeddings_chunked[word])\n",
    "    print(len(x))\n",
    "    try:\n",
    "        x_std = StandardScaler().fit_transform(x)\n",
    "        pca.fit_transform(x_std)\n",
    "        word_embeddings_pca[word]=pca.singular_values_\n",
    "#         print(len(pca.singular_values_))\n",
    "    except ValueError:\n",
    "        # print(word_embeddings_chunked[word])\n",
    "        print(\"UH OH\")\n",
    "\n",
    "pickle.dump(word_embeddings_pca,open(\"feature-extraction/embed-extractor/word_embedding_vectors_pca.pickle\",\"wb\"))\n",
    "for word in word_embeddings_pca:\n",
    "    if len(word_embeddings_pca[word])!=16:\n",
    "        print(\"OH!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_opinion_column(df, strongly_subj_list):\n",
    "    #add a binary column where opinion == 1 if the tweet text contains a strongly subjective word\n",
    "    #global strongly_subj_list\n",
    "    OpinionExtractor.add_opinion_column(df, strongly_subj_list)\n",
    "\n",
    "def extract_user_column(row):\n",
    "    global user_labels\n",
    "        \n",
    "    user_dict = row['user']\n",
    "    \n",
    "    for col in user_dict.keys():\n",
    "        user_labels.append(col)\n",
    "\n",
    "def update_user_column(row):\n",
    "    global user_vals\n",
    "    user_dict = row['user']\n",
    "    \n",
    "    for key in user_vals.keys():\n",
    "#         print(key)\n",
    "        concat_key = key[5:]\n",
    "        if concat_key in user_dict:\n",
    "#             print(sup)\n",
    "            val = user_dict[concat_key]\n",
    "            user_vals[key].append(val)\n",
    "        else:\n",
    "            user_vals[key].append(np.nan)\n",
    "            \n",
    "def convert_date(row):\n",
    "    date = row['user_created_at'].split()\n",
    "    date_str = ' '.join([date[1], date[2], date[-1]])\n",
    "    \n",
    "    datetime_object = datetime.strptime(date_str, '%b %d %Y')\n",
    "    date_int = datetime_object.year * 10000 + datetime_object.month * 100 + datetime_object.day\n",
    "        \n",
    "    return date_int\n",
    "\n",
    "def convert_to_int(row, col):\n",
    "    return int(row[col])\n",
    "\n",
    "def normalize_column(df, col):\n",
    "    col_array = np.asarray(df[col].tolist())\n",
    "    mean = np.mean(col_array)\n",
    "    std = np.std(col_array)\n",
    "    col_array = (col_array - mean) / float(std)\n",
    "    \n",
    "    df[col] = col_array\n",
    "    \n",
    "def create_user_features(df):\n",
    "\n",
    "    global user_labels\n",
    "    global user_vals\n",
    "    user_labels = []\n",
    "    df.apply(extract_user_column, axis = 1)\n",
    "    user_labels = ['user_' + label for label in set(user_labels)]\n",
    "    user_vals = {label:[] for label in user_labels}\n",
    "    \n",
    "    df.apply(update_user_column, axis = 1) \n",
    "    \n",
    "    user_df = pd.DataFrame(user_vals)\n",
    "    user_df['user_created'] = user_df.apply(convert_date, axis = 1)\n",
    "\n",
    "    col_list = ['user_default_profile', \n",
    "                'user_favourites_count', 'user_followers_count', 'user_friends_count', 'user_geo_enabled',\n",
    "                'user_listed_count', 'user_statuses_count', 'user_verified','user_created']\n",
    "\n",
    "    for col in col_list:\n",
    "        user_df[col] = user_df.apply(lambda x : convert_to_int(x, col), axis = 1)\n",
    "\n",
    "    # normalize_column(user_df, col)\n",
    "    user_df = user_df[col_list]    \n",
    "\n",
    "    norm_list = ['user_favourites_count', 'user_followers_count', 'user_friends_count',\n",
    "                'user_listed_count', 'user_statuses_count','user_created']\n",
    "\n",
    "    for col in norm_list:\n",
    "        normalize_column(user_df, col)\n",
    "\n",
    "    df = pd.concat([df.reset_index(), user_df], axis = 1)\n",
    "    df = df.set_index('index')\n",
    "\n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('feature-extraction/embed-extractor/word_embedding_vectors.pickle', 'rb') as pickle_file:\n",
    "    ee = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key = 500288349924782080   9000\n",
      "key = 500308076004929537   9000\n",
      "key = 544282227035869184   9000\n",
      "key = 529695367680761856   9000\n",
      "key = 544324444773433348   9000\n",
      "key = 544350712365207552   9000\n",
      "key = 500389488217309184   9000\n",
      "key = 552806309540528128   9000\n",
      "key = 552978099357237248   9000\n",
      "key = 524956129017995264   9000\n",
      "key = 500332933098385408   9000\n",
      "key = 544271362022338560   9000\n",
      "key = 544514564407427072   9000\n",
      "key = 553587672137334785   9000\n",
      "key = 500363126294863876   9000\n",
      "key = 553474188259102720   9000\n",
      "key = 500394061887709184   9000\n",
      "key = 544309275141885952   9000\n",
      "key = 552811386259386370   9000\n",
      "key = 524925987239120897   9000\n",
      "key = 576323086888361984   9000\n",
      "key = 544314234541469696   9000\n",
      "key = 544381485591982083   9000\n",
      "key = 553505242554175489   9000\n",
      "key = 544278985249550337   9000\n",
      "key = 553586897168392192   9000\n",
      "key = 524975705206304769   9000\n",
      "key = 529653029747064832   9000\n",
      "key = 577258317942149120   9000\n",
      "key = 544367462012432384   9000\n",
      "key = 529654186791944192   9000\n",
      "key = 552792913910833152   9000\n",
      "key = 524923462398513152   9000\n",
      "key = 524952883343925249   9000\n",
      "key = 544491151118860289   9000\n",
      "key = 544515538383564801   9000\n",
      "key = 524925050739490816   9000\n",
      "key = 500280422295937024   9000\n",
      "key = 553486439129038848   9000\n",
      "key = 552848620375261184   9000\n",
      "key = 499366666300846081   9000\n",
      "key = 544297696308518912   9000\n",
      "key = 529739968470867968   9000\n",
      "key = 500354773133299713   9000\n",
      "key = 500377145349521411   9000\n",
      "key = 524937542131793920   9000\n",
      "key = 553534838880608256   9000\n",
      "key = 544290258951892992   9000\n",
      "key = 544512108885725184   9000\n",
      "key = 544374511194632192   9000\n",
      "key = 553590835850514433   9000\n",
      "key = 524926235030589440   9000\n",
      "key = 524990163446140928   9000\n",
      "key = 524991576163250176   9000\n",
      "key = 544292670336925696   9000\n",
      "key = 524924619812511746   9000\n",
      "key = 500378223977721856   9000\n",
      "key = 576276947648405505   9000\n",
      "key = 553501357156876290   9000\n",
      "key = 524993533212897281   9000\n",
      "key = 500327106824245249   9000\n",
      "key = 552996335319007233   9000\n",
      "key = 552805488631758849   9000\n",
      "key = 500298752469770240   9000\n",
      "key = 525019752507658240   9000\n",
      "key = 552821069036670976   9000\n",
      "key = 553588178687655936   9000\n",
      "key = 524931324763992064   9000\n",
      "key = 498280126254428160   9000\n",
      "key = 500319675797209088   9000\n",
      "key = 524923676484177920   9000\n",
      "key = 552785375161499649   9000\n",
      "key = 524959809402331137   9000\n",
      "key = 499530130487017472   9000\n",
      "key = 553476490315431937   9000\n",
      "key = 544319832486064128   9000\n",
      "key = 525060425184858112   9000\n",
      "key = 553461741917863936   9000\n",
      "key = 552816020403269632   9000\n",
      "key = 553575232867672064   9000\n",
      "key = 544329935943237632   9000\n",
      "key = 544293753130082305   9000\n",
      "key = 544380742076088320   9000\n",
      "key = 544382892378714113   9000\n",
      "key = 524927281048080385   9000\n",
      "key = 553548567420628992   9000\n",
      "key = 500378522788315137   9000\n",
      "key = 544277117039837184   9000\n",
      "key = 552982613288157184   9000\n",
      "key = 525032872647065600   9000\n",
      "key = 552783667052167168   9000\n",
      "key = 525003468659228672   9000\n",
      "key = 544358533819420672   9000\n",
      "key = 552802654641225728   9000\n",
      "key = 553566026030272512   9000\n",
      "key = 552834961762709505   9000\n",
      "key = 544391533240516608   9000\n",
      "key = 529540733020405760   9000\n",
      "key = 552791578893619200   9000\n",
      "key = 553221600955621376   9000\n",
      "key = 544289941996326912   9000\n",
      "key = 553212962044149761   9000\n",
      "key = 544350567183556608   9000\n",
      "key = 553467311261503488   9000\n",
      "key = 525025279803424768   9000\n",
      "key = 524995771587108864   9000\n",
      "key = 524965775036387329   9000\n",
      "key = 500303431928922113   9000\n",
      "key = 553518472798683136   9000\n",
      "key = 500281094239817728   9000\n",
      "key = 500307001629745152   9000\n",
      "key = 529716453792956416   9000\n",
      "key = 500347114975944705   9000\n",
      "key = 544305540286148609   9000\n",
      "key = 544511199702822913   9000\n",
      "key = 553512735192141826   9000\n",
      "key = 500278045597368320   9000\n",
      "key = 524983581983375360   9000\n",
      "key = 552978184413921281   9000\n",
      "key = 553506608203169792   9000\n",
      "key = 544268732046913536   9000\n",
      "key = 553550301886955520   9000\n",
      "key = 544291804057960448   9000\n",
      "key = 544514570367168512   9000\n",
      "key = 553152395371630592   9000\n",
      "key = 500377906305327104   9000\n",
      "key = 544306719686656000   9000\n",
      "key = 553579224402235393   9000\n",
      "key = 552814494381256704   9000\n",
      "key = 525056576038518785   9000\n",
      "key = 524947867975561216   9000\n",
      "key = 524966904885428226   9000\n",
      "key = 576812998418939904   9000\n",
      "key = 576755174531862529   9000\n",
      "key = 553544694765215745   9000\n",
      "key = 576513463738109954   9000\n",
      "key = 553107921081749504   9000\n",
      "key = 544282005941530624   9000\n",
      "key = 544512910538838016   9000\n",
      "key = 544510450101415936   9000\n",
      "key = 553558982476828674   9000\n",
      "key = 525068915068923904   9000\n",
      "key = 529689679411810304   9000\n",
      "key = 524925215235911680   9000\n",
      "key = 524980744658382848   9000\n",
      "key = 500258409988763649   9000\n",
      "key = 525028734991343617   9000\n",
      "key = 544272537341812736   9000\n",
      "key = 524940659778920448   9000\n",
      "key = 544352727971954690   9000\n",
      "key = 544271284796784640   9000\n",
      "key = 544287209730236416   9000\n",
      "key = 553586860334010368   9000\n",
      "key = 553184482241814530   9000\n",
      "key = 553508098825261056   9000\n",
      "key = 553549686129561600   9000\n",
      "key = 544517264054423552   9000\n",
      "key = 544328894812549121   9000\n",
      "key = 529713467184676864   9000\n",
      "key = 553160652567498752   9000\n",
      "key = 529695483661664257   9000\n",
      "key = 552791196247269378   9000\n",
      "key = 529660296080916480   9000\n",
      "key = 544518335019229184   9000\n",
      "key = 552832817089236992   9000\n",
      "key = 500294803402137600   9000\n",
      "key = 500341884678836224   9000\n",
      "key = 544504183341064192   9000\n",
      "key = 544305745416581120   9000\n",
      "key = 521360486387175424   9000\n",
      "key = 524943490887991296   9000\n",
      "key = 552810448324943872   9000\n",
      "key = 500290456845299714   9000\n",
      "key = 544271069146656768   9000\n",
      "key = 544291965513134080   9000\n",
      "key = 553476880339599360   9000\n",
      "key = 500270780832174080   9000\n",
      "key = 524970851675176960   9000\n",
      "key = 552984502063337472   9000\n",
      "key = 524932056560963584   9000\n",
      "key = 524941132237910016   9000\n",
      "key = 500280838710247424   9000\n",
      "key = 500284699546517505   9000\n",
      "key = 544301453717041152   9000\n",
      "key = 500295393301647360   9000\n",
      "key = 500391222075076610   9000\n",
      "key = 544399927045283840   9000\n",
      "key = 544283772569788416   9000\n",
      "key = 500363740311982081   9000\n",
      "key = 524969201102901248   9000\n",
      "key = 553576010898497536   9000\n",
      "key = 498430783699554305   9000\n",
      "key = 500286058664579072   9000\n",
      "key = 521346721226711040   9000\n",
      "key = 499612545909415938   9000\n",
      "key = 576319832800555008   9000\n",
      "key = 524962142563610625   9000\n",
      "key = 499456140044824576   9000\n",
      "key = 529720273285566464   9000\n",
      "key = 552806757672964097   9000\n",
      "key = 524947674164760577   9000\n",
      "key = 524935485370929152   9000\n",
      "key = 544288681021145090   9000\n",
      "key = 500319801344929795   9000\n",
      "key = 576829262927413248   9000\n",
      "key = 524929497205055488   9000\n",
      "key = 524932935137628160   9000\n",
      "key = 544278335455776769   9000\n",
      "key = 524942470472548352   9000\n",
      "key = 544462330105712640   9000\n",
      "key = 552792544132997121   9000\n",
      "key = 524964948683005952   9000\n",
      "key = 500279160795721728   9000\n",
      "key = 553544252563935234   9000\n",
      "key = 544274934835707905   9000\n",
      "key = 500381163866062848   9000\n",
      "key = 500327120770301952   9000\n",
      "key = 553489393202499584   9000\n",
      "key = 553164985460068352   9000\n",
      "key = 544512664769396736   9000\n",
      "key = 552792802309181440   9000\n",
      "key = 544277860555710464   9000\n",
      "key = 576796432730071040   9000\n",
      "key = 524981436252950528   9000\n",
      "key = 524972443308683264   9000\n",
      "key = 500413818368184321   9000\n",
      "key = 553470492565602305   9000\n",
      "key = 553535829017370625   9000\n",
      "key = 553587013409325058   9000\n",
      "key = 544289311504355328   9000\n",
      "key = 500371149713178625   9000\n",
      "key = 544513524438155264   9000\n",
      "key = 525049639016615937   9000\n",
      "key = 553478289474740224   9000\n",
      "key = 500281131057811456   9000\n",
      "key = 553538058440941568   9000\n",
      "key = 524926472432410625   9000\n",
      "key = 525023025792835585   9000\n",
      "key = 524936872666353664   9000\n",
      "key = 544269749405097984   9000\n",
      "key = 553503184174710784   9000\n",
      "key = 544306402731507712   9000\n",
      "key = 552793679082311680   9000\n",
      "key = 524949443607412737   9000\n",
      "key = 553543369604210689   9000\n",
      "key = 544520273718812672   9000\n",
      "key = 524947416869388288   9000\n",
      "key = 499368931367608320   9000\n",
      "key = 544310853613281281   9000\n",
      "key = 524948866773184512   9000\n",
      "key = 544358564484378624   9000\n",
      "key = 500279189405433858   9000\n",
      "key = 529687410611728384   9000\n",
      "key = 544289409294553088   9000\n",
      "key = 553531413459660800   9000\n",
      "key = 552833028201144320   9000\n",
      "key = 544391176137089024   9000\n",
      "key = 544520042810200064   9000\n",
      "key = 553589051044151296   9000\n",
      "key = 544292129972170752   9000\n",
      "key = 553587303172833280   9000\n",
      "key = 525025463648137216   9000\n",
      "key = 553197863971610624   9000\n",
      "key = 544319274072817664   9000\n",
      "key = 553590459688570880   9000\n",
      "key = 525058976376193024   9000\n",
      "key = 544512676643500033   9000\n",
      "key = 524925730053181440   9000\n",
      "key = 544476808566276097   9000\n",
      "key = 524944399890124801   9000\n",
      "key = 544333764814323713   9000\n",
      "key = 524922729485848576   9000\n",
      "key = 580325090367315968   9000\n",
      "key = 580348081100734464   9000\n",
      "key = 580324027715063808   9000\n",
      "key = 580319184652890113   9000\n",
      "key = 580333909008871424   9000\n",
      "key = 580321156508577792   9000\n",
      "key = 580320684305416192   9000\n",
      "key = 580333763512705025   9000\n",
      "key = 580340476949086208   9000\n",
      "key = 580339825649291264   9000\n",
      "key = 580360165540642816   9000\n",
      "key = 580322453928431617   9000\n",
      "key = 580882341880446977   9000\n",
      "key = 580326222107951104   9000\n",
      "key = 581473088249958400   9000\n",
      "key = 580371845997682688   9000\n",
      "key = 580331561398108160   9000\n",
      "key = 581047170637381632   9000\n",
      "key = 581293286268129280   9000\n",
      "key = 580332109782466561   9000\n",
      "key = 580319078155468800   9000\n",
      "key = 580339547269144576   9000\n",
      "key = 581386094337474560   9000\n",
      "key = 581063377226637312   9000\n",
      "key = 580323060533764097   9000\n",
      "key = 498293668655423488   9000\n",
      "key = 498486826269548545   9000\n",
      "key = 500280249629036544   9000\n",
      "key = 500298588992593920   9000\n",
      "key = 524923293711998976   9000\n",
      "key = 524936793633083394   9000\n",
      "key = 524941720249978880   9000\n",
      "key = 524948206023880704   9000\n",
      "key = 524961721744900097   9000\n",
      "key = 544274544174071809   9000\n",
      "key = 544294893146091520   9000\n",
      "key = 544315472075042818   9000\n",
      "key = 552788945017516032   9000\n",
      "key = 553480082996879360   9000\n",
      "key = 553553288625672192   9000\n",
      "key = 553561170637238272   9000\n",
      "key = 580352273001410560   9000\n",
      "key = 581153923987206146   9000\n",
      "key = 581290271997968384   9000\n",
      "key = 581359544682614784   9000\n",
      "key = 758159624122097664   9000\n",
      "key = 763098277986209792   9000\n",
      "key = 764927075522260992   9000\n",
      "key = 767725956706414592   9000\n",
      "key = 768859780240773121   9000\n",
      "key = 769988636754505729   9000\n",
      "key = 774991078265094144   9000\n",
      "key = 775057555865206784   9000\n"
     ]
    }
   ],
   "source": [
    "for e in ee.keys():\n",
    "\n",
    "        print(\"key = \" + str(e) + \"   \" + str(len(ee[e])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ee = EmbedExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(column_name, df):\n",
    "    std = df[column_name].std()\n",
    "    norm_col = df[column_name].apply(lambda x: x - std)\n",
    "    df[column_name] = norm_col\n",
    "\n",
    "# builds the labels and vectorizations of given data\n",
    "#if you want to fool around with including/excluding certain features and whatnot, this is the place to do it\n",
    "\n",
    "def labels_and_vectors(file, index=0):\n",
    "    df = pd.read_pickle(file)\n",
    "    \n",
    "    wordlist = VulgarExtractor.vulgarWords(\"feature-extraction/vulgar-extractor/badwords.txt\") \n",
    "    dftext = df[['text']]\n",
    "    result = dftext.applymap(lambda x: VulgarExtractor.containsVulgar(x,wordlist))\n",
    "    df['isVulgar'] = result\n",
    "\n",
    "    word_embeddings = [ee[key] for key in df.index]\n",
    "    # word_embeddings = [ee.tweetVec(tagged_line) for tagged_line in df['text']]\n",
    "    textlist = [txt.replace('\\n','') for txt in df['text'].tolist()]\n",
    "    tagged_sents = TwitterParser.tag(textlist)\n",
    "    df['POS'] = tagged_sents\n",
    "\n",
    "    processed_sents = []\n",
    "    for tagged_sent in df['POS']:\n",
    "        processed_words = []\n",
    "        for word, tag in tagged_sent:\n",
    "            if tag == 'U':\n",
    "                processed_words.append('someurl')\n",
    "            elif tag == '@':\n",
    "                processed_words.append('@someuser')\n",
    "            else:\n",
    "                processed_words.append(word)\n",
    "        sent = ' '.join(processed_words)\n",
    "        processed_sents.append(sent)\n",
    "    df['text'] = processed_sents\n",
    "\n",
    "    word_counts = [TwitterParser.word_count(tagged_line) for tagged_line in df['POS']]\n",
    "    pos_count_list = [TwitterParser.pos_counts(tagged_line) for tagged_line in df['POS']]\n",
    "    contains_adjs = [TwitterParser.contains_adjectives(tagged_line) for tagged_line in df['POS']]\n",
    "    contains_urls = [TwitterParser.contains_url(tagged_line) for tagged_line in df['POS']]\n",
    "    contains_emojis = [TwitterParser.contains_emoji(tagged_line) for tagged_line in df['POS']]\n",
    "    contains_abbrevs = [TwitterParser.contains_abbreviation(tagged_line) for tagged_line in df['POS']]\n",
    "\n",
    "    df['wordCount'] = word_counts\n",
    "    df['posCounts'] = pos_count_list\n",
    "    df['containsAdjective'] = contains_adjs\n",
    "    df['containsURL'] = contains_urls\n",
    "    df['containsEmoji'] = contains_emojis\n",
    "    df['containsAbbreviation'] = contains_abbrevs\n",
    "    df['wordEmbedding'] = word_embeddings\n",
    "\n",
    "    \n",
    "    for i, tag in enumerate(TwitterParser.tagset):\n",
    "        tag_counts = []\n",
    "        for pos_counts in df['posCounts']:\n",
    "            tag_counts.append(pos_counts[i])\n",
    "        column_name = 'num_' + tag\n",
    "        df[column_name] = tag_counts\n",
    "        normalize(column_name, df)\n",
    "    \n",
    "#     global strongly_subj_list\n",
    "    strongly_subj_list = OpinionExtractor.initialize_subjectivity()\n",
    "    create_opinion_column(df, strongly_subj_list)\n",
    "    df = create_user_features(df)    \n",
    "        \n",
    "    # Changes \"true\"/\"false\"/\"unverified\" to numeric values, just like the in the early cells\n",
    "    df.loc[df.classification == 'true', 'classification'] = 1\n",
    "    df.loc[df.classification == 'false', 'classification'] = 0\n",
    "    df.loc[df.classification == 'unverified', 'classification'] = 2\n",
    "    # getting the labels\n",
    "\n",
    "    #removed containsURL\n",
    "    attributes = ['isVulgar', 'containsAdjective', 'containsURL', 'containsEmoji', 'containsAbbreviation', 'wordCount']\n",
    "    for tag in TwitterParser.tagset:\n",
    "        attributes.append('num_' + tag)\n",
    "        \n",
    "        \n",
    "    attributes = attributes + ['num_replies', 're_has_?', 're_has_NOT', 're_has_correct',\n",
    " 're_has_credib', 're_has_data', 're_has_detail', 're_has_fabricat', 're_has_lie', 're_has_proof', \n",
    "                  're_has_source', 're_has_witness']\n",
    "                               \n",
    "# 'opinion', 'user_default_profile',\n",
    "#  'user_favourites_count', 'user_followers_count', 'user_friends_count', 'user_geo_enabled', 'user_listed_count', \n",
    "#                   'user_statuses_count', 'user_verified', 'user_created']\n",
    "#     print(df.columns.values)\n",
    "        \n",
    "        \n",
    "    labels = df['classification']\n",
    "    labels = [l for l in labels]\n",
    "    labels = np.array(labels)\n",
    "\n",
    "\n",
    "    # getting the values as a list of lists\n",
    "    values = df[attributes].values.tolist()\n",
    "    word_embedding_values = df['wordEmbedding'].values.tolist()\n",
    "\n",
    "\n",
    "#     #Below puts the tweet ID as a feature. Comment this out if you aren't using tweetID\n",
    "#     for i,index in enumerate(df.index):\n",
    "#         dev_values[i].append(int(index))\n",
    "\n",
    "\n",
    "#UNCOMMENT THIS IN ORDER TO INCOPORATE WORD_EMBEDDINGS AGAIN\n",
    "    for i,d in enumerate(word_embedding_values):\n",
    "        values[i].extend(d)\n",
    "\n",
    "    values = np.array(values)\n",
    "    if index == 1:\n",
    "        return df.index, values\n",
    "    \n",
    "    \n",
    "    return labels, values\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that the indices of labels-to-values should not be mismatched\n",
    "tr_labels, tr_values = labels_and_vectors('output/full/train_data_full.pickle')\n",
    "indices, dev_values = labels_and_vectors('output/full/goldtest_data_full.pickle', index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(272, 9043)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change classifier here\n",
    "predictions, probabilities = classifiers.random_forest(tr_values, tr_labels, dev_values, 80, 3, \"gini\")\n",
    "ps = []\n",
    "\n",
    "# need to convert the numerical predictions back into their string values\n",
    "for i, p in enumerate(predictions):\n",
    "    if p == 0:\n",
    "        ps.append('false')\n",
    "    if p == 1:\n",
    "        ps.append('true')\n",
    "    if p == 2:\n",
    "        ps.append('unverified')\n",
    "\n",
    "# creates pairings of the prediction and the probability of the prediction\n",
    "pred_probs_pairs = [[ps[i], probabilities[i][predictions[i]]] for i in range(len(predictions))] \n",
    "#attaches the tweetID (called reference_id in the score.py file)\n",
    "pred_dict = {index:pred_probs_pairs[i] for i,index in enumerate(indices)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_dir = './output/classifier_output/'\n",
    "try:\n",
    "    os.stat(output_dir)\n",
    "except:\n",
    "    os.mkdir(output_dir)  \n",
    "\n",
    "with open('output/classifier_output/goldtest_nb.json', 'w') as outfile:\n",
    "    json.dump(pred_dict, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 entries in reference file\r\n",
      "matching entry: 775057555865206784\r\n",
      "matching entry: 498486826269548545\r\n",
      "matching entry: 774991078265094144\r\n",
      "matching entry: 524948206023880704\r\n",
      "matching entry: 769988636754505729\r\n",
      "matching entry: 544315472075042818\r\n",
      "matching entry: 524936793633083394\r\n",
      "matching entry: 553561170637238272\r\n",
      "matching entry: 763098277986209792\r\n",
      "matching entry: 498293668655423488\r\n",
      "matching entry: 524941720249978880\r\n",
      "matching entry: 553553288625672192\r\n",
      "matching entry: 764927075522260992\r\n",
      "matching entry: 544274544174071809\r\n",
      "matching entry: 758159624122097664\r\n",
      "matching entry: 552788945017516032\r\n",
      "matching entry: 500280249629036544\r\n",
      "matching entry: 580352273001410560\r\n",
      "matching entry: 500298588992593920\r\n",
      "matching entry: 524923293711998976\r\n",
      "matching entry: 553480082996879360\r\n",
      "matching entry: 544294893146091520\r\n",
      "matching entry: 767725956706414592\r\n",
      "matching entry: 581153923987206146\r\n",
      "matching entry: 581359544682614784\r\n",
      "matching entry: 524961721744900097\r\n",
      "matching entry: 768859780240773121\r\n",
      "matching entry: 581290271997968384\r\n",
      "28 matched entries in submission\r\n",
      "28 entries in reference file\r\n",
      "veracity accuracy: 0.25\r\n",
      "Micro F1: 0.25\r\n",
      "confidence rmse:   0.7950321675820263\r\n"
     ]
    }
   ],
   "source": [
    "!python3 scorer/score.py data/semeval2017-task8-dataset/goldtest/subtaskb.json output/classifier_output/goldtest_nb.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
