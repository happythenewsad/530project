{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FileReader import FileReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classInstance = FileReader\n",
    "df_list = classInstance.get_dataframe() #IMPORTANT:  saves a pickle to output/simple or output/full. \n",
    "\n",
    "#The pickle is the same as df.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTANT NOTE:\n",
    "\n",
    "Word embeddings are expressed as pickle files.\n",
    "Reading of tweet data is converted to a Pandas Dataframe format and then finally into a pickle file, located output/simple or output/full.\n",
    "\n",
    "It is important that you first execute file_reader.py and *then* this notebook, run_tests.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(1, \"./feature-extraction/embed-extractor\")\n",
    "from EmbedExtractor import EmbedExtractor\n",
    "sys.path.insert(1, \"./feature-extraction/vulgar-extractor\")\n",
    "from VulgarExtractor import VulgarExtractor\n",
    "sys.path.insert(1, \"./feature-extraction/twitter-parser\")\n",
    "from TwitterParser import TwitterParser\n",
    "sys.path.insert(1, \"./feature-extraction/opinion-extractor/\")\n",
    "from OpinionExtractor import OpinionExtractor\n",
    "from sklearn import decomposition\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "import classifiers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TabError",
     "evalue": "inconsistent use of tabs and spaces in indentation (<ipython-input-21-66c8d2850c3a>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-21-66c8d2850c3a>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    avg = len(seq) / float(num)\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mTabError\u001b[0m\u001b[0;31m:\u001b[0m inconsistent use of tabs and spaces in indentation\n"
     ]
    }
   ],
   "source": [
    "# Run this cell to generate the pre-PCA and post-PCA word embeddings\n",
    "print(\"oh\")\n",
    "def chunkIt(seq, num):\n",
    "    print(len(seq))\n",
    "\tavg = len(seq) / float(num)\n",
    "\tout = []\n",
    "\tlast = 0.0\n",
    "\tzeros = [0]*int(avg)\n",
    "\n",
    "\twhile last < len(seq):\n",
    "\t\tsubVector = seq[int(last):int(last + avg)]\n",
    "\t\tif zeros==subVector and last>4700:\n",
    "\t\t\tbreak\n",
    "\t\tout.append(subVector)\n",
    "\t\tlast += avg\n",
    "\treturn out\n",
    "\n",
    "# ####UNCOMMENT THIS TO RUN THE EE#####\n",
    "# ee = EmbedExtractor()\n",
    "# tweet2vec = {}\n",
    "    \n",
    "# for d in [\"train\",\"dev\",\"test\"]:\n",
    "# \twith open('./output/full/'+d+'_data_full.json', 'r') as f:\n",
    "# \t    jstr = f.read()\n",
    "\n",
    "# \tj = json.loads(jstr)\n",
    "\n",
    "# \tfor key in j:\n",
    "# \t\ttweet=j[key]['text']\n",
    "# \t\ttweet2vec[key]=ee.tweetVec(tweet)\n",
    "# pickleFile=\"feature-extraction/embed-extractor/word_embedding_vectors.pickle\"\n",
    "# pickle.dump(tweet2vec,open(pickleFile,\"wb\"))\n",
    "# ##########################################\n",
    "\n",
    "\n",
    "word_embeddings_pca = {}\n",
    "pickleFile=\"feature-extraction/embed-extractor/word_embedding_vectors.pickle\"\n",
    "word_embeddings = pd.read_pickle(pickleFile)\n",
    "\n",
    "word_embeddings_chunked = {}\n",
    "for word in word_embeddings:\n",
    "    word_embeddings_chunked[word]=chunkIt(word_embeddings[word],30)\n",
    "for word in word_embeddings_chunked:\n",
    "    pca = decomposition.PCA(n_components=24)\n",
    "    x = np.array(word_embeddings_chunked[word])\n",
    "    print(len(x))\n",
    "    try:\n",
    "        x_std = StandardScaler().fit_transform(x)\n",
    "        pca.fit_transform(x_std)\n",
    "        word_embeddings_pca[word]=pca.singular_values_\n",
    "#         print(len(pca.singular_values_))\n",
    "    except ValueError:\n",
    "        # print(word_embeddings_chunked[word])\n",
    "        print(\"UH OH\")\n",
    "\n",
    "pickle.dump(word_embeddings_pca,open(\"feature-extraction/embed-extractor/word_embedding_vectors_pca.pickle\",\"wb\"))\n",
    "for word in word_embeddings_pca:\n",
    "    if len(word_embeddings_pca[word])!=16:\n",
    "        print(\"OH!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_opinion_column(df, strongly_subj_list):\n",
    "    #add a binary column where opinion == 1 if the tweet text contains a strongly subjective word\n",
    "    #global strongly_subj_list\n",
    "    OpinionExtractor.add_opinion_column(df, strongly_subj_list)\n",
    "\n",
    "def extract_user_column(row):\n",
    "    global user_labels\n",
    "        \n",
    "    user_dict = row['user']\n",
    "    \n",
    "    for col in user_dict.keys():\n",
    "        user_labels.append(col)\n",
    "\n",
    "def update_user_column(row):\n",
    "    global user_vals\n",
    "    user_dict = row['user']\n",
    "    \n",
    "    for key in user_vals.keys():\n",
    "#         print(key)\n",
    "        concat_key = key[5:]\n",
    "        if concat_key in user_dict:\n",
    "#             print(sup)\n",
    "            val = user_dict[concat_key]\n",
    "            user_vals[key].append(val)\n",
    "        else:\n",
    "            user_vals[key].append(np.nan)\n",
    "            \n",
    "def convert_date(row):\n",
    "    date = row['user_created_at'].split()\n",
    "    date_str = ' '.join([date[1], date[2], date[-1]])\n",
    "    \n",
    "    datetime_object = datetime.strptime(date_str, '%b %d %Y')\n",
    "    date_int = datetime_object.year * 10000 + datetime_object.month * 100 + datetime_object.day\n",
    "        \n",
    "    return date_int\n",
    "\n",
    "def convert_to_int(row, col):\n",
    "    return int(row[col])\n",
    "\n",
    "def normalize_column(df, col):\n",
    "    col_array = np.asarray(df[col].tolist())\n",
    "    mean = np.mean(col_array)\n",
    "    std = np.std(col_array)\n",
    "    col_array = (col_array - mean) / float(std)\n",
    "    \n",
    "    df[col] = col_array\n",
    "    \n",
    "def create_user_features(df):\n",
    "\n",
    "    global user_labels\n",
    "    global user_vals\n",
    "    user_labels = []\n",
    "    df.apply(extract_user_column, axis = 1)\n",
    "    user_labels = ['user_' + label for label in set(user_labels)]\n",
    "    user_vals = {label:[] for label in user_labels}\n",
    "    \n",
    "    df.apply(update_user_column, axis = 1) \n",
    "    \n",
    "    user_df = pd.DataFrame(user_vals)\n",
    "    user_df['user_created'] = user_df.apply(convert_date, axis = 1)\n",
    "\n",
    "    col_list = ['user_default_profile', \n",
    "                'user_favourites_count', 'user_followers_count', 'user_friends_count', 'user_geo_enabled',\n",
    "                'user_listed_count', 'user_statuses_count', 'user_verified','user_created']\n",
    "\n",
    "    for col in col_list:\n",
    "        user_df[col] = user_df.apply(lambda x : convert_to_int(x, col), axis = 1)\n",
    "\n",
    "    # normalize_column(user_df, col)\n",
    "    user_df = user_df[col_list]    \n",
    "\n",
    "    norm_list = ['user_favourites_count', 'user_followers_count', 'user_friends_count',\n",
    "                'user_listed_count', 'user_statuses_count','user_created']\n",
    "\n",
    "    for col in norm_list:\n",
    "        normalize_column(user_df, col)\n",
    "\n",
    "    df = pd.concat([df.reset_index(), user_df], axis = 1)\n",
    "    df = df.set_index('index')\n",
    "\n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('feature-extraction/embed-extractor/word_embedding_vectors_pca.pickle', 'rb') as pickle_file:\n",
    "    ee = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key = 500394061887709184   18\n",
      "key = 500281094239817728   18\n",
      "key = 499456140044824576   18\n",
      "key = 500279160795721728   18\n",
      "key = 580332109782466561   18\n"
     ]
    }
   ],
   "source": [
    "for e in ee.keys():\n",
    "    if len(ee[e]) != 16:\n",
    "        print(\"key = \" + str(e) + \"   \" + str(len(ee[e])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(column_name, df):\n",
    "    std = df[column_name].std()\n",
    "    norm_col = df[column_name].apply(lambda x: x - std)\n",
    "    df[column_name] = norm_col\n",
    "\n",
    "# builds the labels and vectorizations of given data\n",
    "#if you want to fool around with including/excluding certain features and whatnot, this is the place to do it\n",
    "\n",
    "def labels_and_vectors(file, index=0):\n",
    "    df = pd.read_pickle(file)\n",
    "    \n",
    "    wordlist = VulgarExtractor.vulgarWords(\"feature-extraction/vulgar-extractor/badwords.txt\") \n",
    "    dftext = df[['text']]\n",
    "    result = dftext.applymap(lambda x: VulgarExtractor.containsVulgar(x,wordlist))\n",
    "    df['isVulgar'] = result\n",
    "\n",
    "    word_embeddings = [ee[key] for key in df.index]\n",
    "    # word_embeddings = [ee.tweetVec(tagged_line) for tagged_line in df['text']]\n",
    "    textlist = [txt.replace('\\n','') for txt in df['text'].tolist()]\n",
    "    tagged_sents = TwitterParser.tag(textlist)\n",
    "    df['POS'] = tagged_sents\n",
    "\n",
    "    processed_sents = []\n",
    "    for tagged_sent in df['POS']:\n",
    "        processed_words = []\n",
    "        for word, tag in tagged_sent:\n",
    "            if tag == 'U':\n",
    "                processed_words.append('someurl')\n",
    "            elif tag == '@':\n",
    "                processed_words.append('@someuser')\n",
    "            else:\n",
    "                processed_words.append(word)\n",
    "        sent = ' '.join(processed_words)\n",
    "        processed_sents.append(sent)\n",
    "    df['text'] = processed_sents\n",
    "\n",
    "    word_counts = [TwitterParser.word_count(tagged_line) for tagged_line in df['POS']]\n",
    "    pos_count_list = [TwitterParser.pos_counts(tagged_line) for tagged_line in df['POS']]\n",
    "    contains_adjs = [TwitterParser.contains_adjectives(tagged_line) for tagged_line in df['POS']]\n",
    "    contains_urls = [TwitterParser.contains_url(tagged_line) for tagged_line in df['POS']]\n",
    "    contains_emojis = [TwitterParser.contains_emoji(tagged_line) for tagged_line in df['POS']]\n",
    "    contains_abbrevs = [TwitterParser.contains_abbreviation(tagged_line) for tagged_line in df['POS']]\n",
    "\n",
    "    df['wordCount'] = word_counts\n",
    "    df['posCounts'] = pos_count_list\n",
    "    df['containsAdjective'] = contains_adjs\n",
    "    df['containsURL'] = contains_urls\n",
    "    df['containsEmoji'] = contains_emojis\n",
    "    df['containsAbbreviation'] = contains_abbrevs\n",
    "    df['wordEmbedding'] = word_embeddings\n",
    "\n",
    "    \n",
    "    for i, tag in enumerate(TwitterParser.tagset):\n",
    "        tag_counts = []\n",
    "        for pos_counts in df['posCounts']:\n",
    "            tag_counts.append(pos_counts[i])\n",
    "        column_name = 'num_' + tag\n",
    "        df[column_name] = tag_counts\n",
    "        normalize(column_name, df)\n",
    "    \n",
    "#     global strongly_subj_list\n",
    "    strongly_subj_list = OpinionExtractor.initialize_subjectivity()\n",
    "    create_opinion_column(df, strongly_subj_list)\n",
    "    df = create_user_features(df)    \n",
    "        \n",
    "    # Changes \"true\"/\"false\"/\"unverified\" to numeric values, just like the in the early cells\n",
    "    df.loc[df.classification == 'true', 'classification'] = 1\n",
    "    df.loc[df.classification == 'false', 'classification'] = 0\n",
    "    df.loc[df.classification == 'unverified', 'classification'] = 2\n",
    "    # getting the labels\n",
    "\n",
    "    #removed containsURL\n",
    "    attributes = ['isVulgar', 'containsAdjective', 'containsURL', 'containsEmoji', 'containsAbbreviation', 'wordCount']\n",
    "    for tag in TwitterParser.tagset:\n",
    "        attributes.append('num_' + tag)\n",
    "        \n",
    "        \n",
    "    attributes = attributes + ['num_replies', 're_has_?', 're_has_NOT', 're_has_correct',\n",
    " 're_has_credib', 're_has_data', 're_has_detail', 're_has_fabricat', 're_has_lie', 're_has_proof', \n",
    "                  're_has_source', 're_has_witness', 'opinion', 'user_default_profile',\n",
    " 'user_favourites_count', 'user_followers_count', 'user_friends_count', 'user_geo_enabled', 'user_listed_count', \n",
    "                  'user_statuses_count', 'user_verified', 'user_created']\n",
    "#     print(df.columns.values)\n",
    "        \n",
    "        \n",
    "    labels = df['classification']\n",
    "    labels = [l for l in labels]\n",
    "    labels = np.array(labels)\n",
    "\n",
    "\n",
    "    # getting the values as a list of lists\n",
    "    values = df[attributes].values.tolist()\n",
    "    word_embedding_values = df['wordEmbedding'].values.tolist()\n",
    "\n",
    "\n",
    "#     #Below puts the tweet ID as a feature. Comment this out if you aren't using tweetID\n",
    "#     for i,index in enumerate(df.index):\n",
    "#        dev_values[i].append(int(index))\n",
    "\n",
    "\n",
    "#UNCOMMENT THIS IN ORDER TO INCOPORATE WORD_EMBEDDINGS AGAIN\n",
    "    for i,d in enumerate(word_embedding_values):\n",
    "        values[i].extend(d)\n",
    "\n",
    "    values = np.array(values)\n",
    "    if index == 1:\n",
    "        return df.index, values\n",
    "    \n",
    "    \n",
    "    return labels, values\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that the indices of labels-to-values should not be mismatched\n",
    "tr_labels, tr_values = labels_and_vectors('output/full/train_data_full.pickle')\n",
    "indices, dev_values = labels_and_vectors('output/full/goldtest_data_full.pickle', index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(272,)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-e8bfa2982c84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#change classifier here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifiers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# need to convert the numerical predictions back into their string values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ncwphilly/Documents/UPENN/SeniorSpring/CIS530/Homework/530project/classifiers.py\u001b[0m in \u001b[0;36mnaive_bayes\u001b[0;34m(x_vectors, x_labels, y_vectors)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnaive_bayes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mprobabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ncwphilly/anaconda/lib/python3.6/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \"\"\"\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m         return self._partial_fit(X, y, np.unique(y), _refit=True,\n\u001b[1;32m    185\u001b[0m                                  sample_weight=sample_weight)\n",
      "\u001b[0;32m/Users/ncwphilly/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    571\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    572\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    574\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/Users/ncwphilly/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    431\u001b[0m                                       force_all_finite)\n\u001b[1;32m    432\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "#change classifier here\n",
    "predictions, probabilities = classifiers.naive_bayes(tr_values, tr_labels, dev_values)\n",
    "ps = []\n",
    "\n",
    "# need to convert the numerical predictions back into their string values\n",
    "for i, p in enumerate(predictions):\n",
    "    if p == 0:\n",
    "        ps.append('false')\n",
    "    if p == 1:\n",
    "        ps.append('true')\n",
    "    if p == 2:\n",
    "        ps.append('unverified')\n",
    "\n",
    "# creates pairings of the prediction and the probability of the prediction\n",
    "pred_probs_pairs = [[ps[i], probabilities[i][predictions[i]]] for i in range(len(predictions))] \n",
    "#attaches the tweetID (called reference_id in the score.py file)\n",
    "pred_dict = {index:pred_probs_pairs[i] for i,index in enumerate(indices)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_dir = './output/classifier_output/'\n",
    "try:\n",
    "    os.stat(output_dir)\n",
    "except:\n",
    "    os.mkdir(output_dir)  \n",
    "\n",
    "with open('output/classifier_output/goldtest_nb.json', 'w') as outfile:\n",
    "    json.dump(pred_dict, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 entries in reference file\r\n",
      "matching entry: 775057555865206784\r\n",
      "matching entry: 498486826269548545\r\n",
      "matching entry: 774991078265094144\r\n",
      "matching entry: 524948206023880704\r\n",
      "matching entry: 769988636754505729\r\n",
      "matching entry: 544315472075042818\r\n",
      "matching entry: 524936793633083394\r\n",
      "matching entry: 553561170637238272\r\n",
      "matching entry: 763098277986209792\r\n",
      "matching entry: 498293668655423488\r\n",
      "matching entry: 524941720249978880\r\n",
      "matching entry: 553553288625672192\r\n",
      "matching entry: 764927075522260992\r\n",
      "matching entry: 544274544174071809\r\n",
      "matching entry: 758159624122097664\r\n",
      "matching entry: 552788945017516032\r\n",
      "matching entry: 500280249629036544\r\n",
      "matching entry: 580352273001410560\r\n",
      "matching entry: 500298588992593920\r\n",
      "matching entry: 524923293711998976\r\n",
      "matching entry: 553480082996879360\r\n",
      "matching entry: 544294893146091520\r\n",
      "matching entry: 767725956706414592\r\n",
      "matching entry: 581153923987206146\r\n",
      "matching entry: 581359544682614784\r\n",
      "matching entry: 524961721744900097\r\n",
      "matching entry: 768859780240773121\r\n",
      "matching entry: 581290271997968384\r\n",
      "28 matched entries in submission\r\n",
      "28 entries in reference file\r\n",
      "veracity accuracy: 0.5\r\n",
      "Micro F1: 0.5\r\n",
      "confidence rmse:   0.7071067811865476\r\n"
     ]
    }
   ],
   "source": [
    "!python3 scorer/score.py data/semeval2017-task8-dataset/goldtest/subtaskb.json output/classifier_output/goldtest_nb.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
