{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from FileReader import FileReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 553480082996879360\n",
      "\n",
      " 581153923987206146\n",
      "\n",
      " 500298588992593920\n",
      "\n",
      " 552788945017516032\n",
      "\n",
      " 524948206023880704\n",
      "\n",
      " 553561170637238272\n",
      "\n",
      " 758159624122097664\n",
      "\n",
      " 767725956706414592\n",
      "\n",
      " 580352273001410560\n",
      "\n",
      " 581359544682614784\n",
      "\n",
      " 763098277986209792\n",
      "\n",
      " 581290271997968384\n",
      "\n",
      " 775057555865206784\n",
      "\n",
      " 500280249629036544\n",
      "\n",
      " 498293668655423488\n",
      "\n",
      " 774991078265094144\n",
      "\n",
      " 553553288625672192\n",
      "\n",
      " 524961721744900097\n",
      "\n",
      " 524941720249978880\n",
      "\n",
      " 544294893146091520\n",
      "\n",
      " 768859780240773121\n",
      "\n",
      " 764927075522260992\n",
      "\n",
      " 544274544174071809\n",
      "\n",
      " 498486826269548545\n",
      "\n",
      " 544315472075042818\n",
      "\n",
      " 524923293711998976\n",
      "\n",
      " 769988636754505729\n",
      "\n",
      " 524936793633083394\n",
      "\n",
      " 553480082996879360\n",
      "\n",
      " 581153923987206146\n",
      "\n",
      " 500298588992593920\n",
      "\n",
      " 552788945017516032\n",
      "\n",
      " 524948206023880704\n",
      "\n",
      " 553561170637238272\n",
      "\n",
      " 758159624122097664\n",
      "\n",
      " 767725956706414592\n",
      "\n",
      " 580352273001410560\n",
      "\n",
      " 581359544682614784\n",
      "\n",
      " 763098277986209792\n",
      "\n",
      " 581290271997968384\n",
      "\n",
      " 775057555865206784\n",
      "\n",
      " 500280249629036544\n",
      "\n",
      " 498293668655423488\n",
      "\n",
      " 774991078265094144\n",
      "\n",
      " 553553288625672192\n",
      "\n",
      " 524961721744900097\n",
      "\n",
      " 524941720249978880\n",
      "\n",
      " 544294893146091520\n",
      "\n",
      " 768859780240773121\n",
      "\n",
      " 764927075522260992\n",
      "\n",
      " 544274544174071809\n",
      "\n",
      " 498486826269548545\n",
      "\n",
      " 544315472075042818\n",
      "\n",
      " 524923293711998976\n",
      "\n",
      " 769988636754505729\n",
      "\n",
      " 524936793633083394\n",
      "{'775057555865206784': 'data/semeval2017-task8-test-data/775057555865206784/', '498486826269548545': 'data/semeval2017-task8-test-data/498486826269548545/', '774991078265094144': 'data/semeval2017-task8-test-data/774991078265094144/', '524948206023880704': 'data/semeval2017-task8-test-data/524948206023880704/', '769988636754505729': 'data/semeval2017-task8-test-data/769988636754505729/', '544315472075042818': 'data/semeval2017-task8-test-data/544315472075042818/', '524936793633083394': 'data/semeval2017-task8-test-data/524936793633083394/', '553561170637238272': 'data/semeval2017-task8-test-data/553561170637238272/', '763098277986209792': 'data/semeval2017-task8-test-data/763098277986209792/', '498293668655423488': 'data/semeval2017-task8-test-data/498293668655423488/', '524941720249978880': 'data/semeval2017-task8-test-data/524941720249978880/', '553553288625672192': 'data/semeval2017-task8-test-data/553553288625672192/', '764927075522260992': 'data/semeval2017-task8-test-data/764927075522260992/', '544274544174071809': 'data/semeval2017-task8-test-data/544274544174071809/', '758159624122097664': 'data/semeval2017-task8-test-data/758159624122097664/', '552788945017516032': 'data/semeval2017-task8-test-data/552788945017516032/', '500280249629036544': 'data/semeval2017-task8-test-data/500280249629036544/', '580352273001410560': 'data/semeval2017-task8-test-data/580352273001410560/', '500298588992593920': 'data/semeval2017-task8-test-data/500298588992593920/', '524923293711998976': 'data/semeval2017-task8-test-data/524923293711998976/', '553480082996879360': 'data/semeval2017-task8-test-data/553480082996879360/', '544294893146091520': 'data/semeval2017-task8-test-data/544294893146091520/', '767725956706414592': 'data/semeval2017-task8-test-data/767725956706414592/', '581153923987206146': 'data/semeval2017-task8-test-data/581153923987206146/', '581359544682614784': 'data/semeval2017-task8-test-data/581359544682614784/', '524961721744900097': 'data/semeval2017-task8-test-data/524961721744900097/', '768859780240773121': 'data/semeval2017-task8-test-data/768859780240773121/', '581290271997968384': 'data/semeval2017-task8-test-data/581290271997968384/'}\n",
      "GOLDTEST ID : <class 'str'>\n",
      "GOLDTEST ID : <class 'str'>\n",
      "GOLDTEST ID : <class 'str'>\n",
      "GOLDTEST ID : <class 'str'>\n",
      "GOLDTEST ID : <class 'str'>\n",
      "GOLDTEST ID : <class 'str'>\n",
      "GOLDTEST ID : <class 'str'>\n",
      "GOLDTEST ID : <class 'str'>\n",
      "GOLDTEST ID : <class 'str'>\n",
      "GOLDTEST ID : <class 'str'>\n",
      "GOLDTEST ID : <class 'str'>\n",
      "GOLDTEST ID : <class 'str'>\n",
      "GOLDTEST ID : <class 'str'>\n",
      "GOLDTEST ID : <class 'str'>\n",
      "GOLDTEST ID : <class 'str'>\n",
      "GOLDTEST ID : <class 'str'>\n",
      "GOLDTEST ID : <class 'str'>\n",
      "GOLDTEST ID : <class 'str'>\n",
      "GOLDTEST ID : <class 'str'>\n",
      "GOLDTEST ID : <class 'str'>\n",
      "GOLDTEST ID : <class 'str'>\n",
      "GOLDTEST ID : <class 'str'>\n",
      "GOLDTEST ID : <class 'str'>\n",
      "GOLDTEST ID : <class 'str'>\n",
      "GOLDTEST ID : <class 'str'>\n",
      "GOLDTEST ID : <class 'str'>\n",
      "GOLDTEST ID : <class 'str'>\n",
      "GOLDTEST ID : <class 'str'>\n",
      "{'775057555865206784': 'data/semeval2017-task8-test-data/775057555865206784/', '498486826269548545': 'data/semeval2017-task8-test-data/498486826269548545/', '774991078265094144': 'data/semeval2017-task8-test-data/774991078265094144/', '524948206023880704': 'data/semeval2017-task8-test-data/524948206023880704/', '769988636754505729': 'data/semeval2017-task8-test-data/769988636754505729/', '544315472075042818': 'data/semeval2017-task8-test-data/544315472075042818/', '524936793633083394': 'data/semeval2017-task8-test-data/524936793633083394/', '553561170637238272': 'data/semeval2017-task8-test-data/553561170637238272/', '763098277986209792': 'data/semeval2017-task8-test-data/763098277986209792/', '498293668655423488': 'data/semeval2017-task8-test-data/498293668655423488/', '524941720249978880': 'data/semeval2017-task8-test-data/524941720249978880/', '553553288625672192': 'data/semeval2017-task8-test-data/553553288625672192/', '764927075522260992': 'data/semeval2017-task8-test-data/764927075522260992/', '544274544174071809': 'data/semeval2017-task8-test-data/544274544174071809/', '758159624122097664': 'data/semeval2017-task8-test-data/758159624122097664/', '552788945017516032': 'data/semeval2017-task8-test-data/552788945017516032/', '500280249629036544': 'data/semeval2017-task8-test-data/500280249629036544/', '580352273001410560': 'data/semeval2017-task8-test-data/580352273001410560/', '500298588992593920': 'data/semeval2017-task8-test-data/500298588992593920/', '524923293711998976': 'data/semeval2017-task8-test-data/524923293711998976/', '553480082996879360': 'data/semeval2017-task8-test-data/553480082996879360/', '544294893146091520': 'data/semeval2017-task8-test-data/544294893146091520/', '767725956706414592': 'data/semeval2017-task8-test-data/767725956706414592/', '581153923987206146': 'data/semeval2017-task8-test-data/581153923987206146/', '581359544682614784': 'data/semeval2017-task8-test-data/581359544682614784/', '524961721744900097': 'data/semeval2017-task8-test-data/524961721744900097/', '768859780240773121': 'data/semeval2017-task8-test-data/768859780240773121/', '581290271997968384': 'data/semeval2017-task8-test-data/581290271997968384/'}\n",
      "GOLDTEST ID : <class 'str'>\n",
      "GOLDTEST ID : <class 'str'>\n",
      "GOLDTEST ID : <class 'str'>\n",
      "GOLDTEST ID : <class 'str'>\n",
      "GOLDTEST ID : <class 'str'>\n",
      "GOLDTEST ID : <class 'str'>\n",
      "GOLDTEST ID : <class 'str'>\n",
      "GOLDTEST ID : <class 'str'>\n",
      "GOLDTEST ID : <class 'str'>\n",
      "GOLDTEST ID : <class 'str'>\n",
      "GOLDTEST ID : <class 'str'>\n",
      "GOLDTEST ID : <class 'str'>\n",
      "GOLDTEST ID : <class 'str'>\n",
      "GOLDTEST ID : <class 'str'>\n",
      "GOLDTEST ID : <class 'str'>\n",
      "GOLDTEST ID : <class 'str'>\n",
      "GOLDTEST ID : <class 'str'>\n",
      "GOLDTEST ID : <class 'str'>\n",
      "GOLDTEST ID : <class 'str'>\n",
      "GOLDTEST ID : <class 'str'>\n",
      "GOLDTEST ID : <class 'str'>\n",
      "GOLDTEST ID : <class 'str'>\n",
      "GOLDTEST ID : <class 'str'>\n",
      "GOLDTEST ID : <class 'str'>\n",
      "GOLDTEST ID : <class 'str'>\n",
      "GOLDTEST ID : <class 'str'>\n",
      "GOLDTEST ID : <class 'str'>\n",
      "GOLDTEST ID : <class 'str'>\n",
      "saving data to output..\n"
     ]
    }
   ],
   "source": [
    "classInstance = FileReader\n",
    "df_list = classInstance.get_dataframe() #IMPORTANT:  saves a pickle to output/simple or output/full. \n",
    "\n",
    "#The pickle is the same as df.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTANT NOTE:\n",
    "\n",
    "Word embeddings are expressed as pickle files.\n",
    "Reading of tweet data is converted to a Pandas Dataframe format and then finally into a pickle file, located output/simple or output/full.\n",
    "\n",
    "It is important that you first execute file_reader.py and *then* this notebook, run_tests.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, \"./feature-extraction/embed-extractor\")\n",
    "from EmbedExtractor import EmbedExtractor\n",
    "sys.path.insert(1, \"./feature-extraction/vulgar-extractor\")\n",
    "from VulgarExtractor import VulgarExtractor\n",
    "sys.path.insert(1, \"./feature-extraction/twitter-parser\")\n",
    "from TwitterParser import TwitterParser\n",
    "import classifiers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee = EmbedExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(column_name, df):\n",
    "    std = df[column_name].std()\n",
    "    norm_col = df[column_name].apply(lambda x: x - std)\n",
    "    df[column_name] = norm_col\n",
    "\n",
    "# builds the labels and vectorizations of given data\n",
    "#if you want to fool around with including/excluding certain features and whatnot, this is the place to do it\n",
    "\n",
    "def labels_and_vectors(file, index=0):\n",
    "    df = pd.read_pickle(file)\n",
    "    \n",
    "    wordlist = VulgarExtractor.vulgarWords(\"feature-extraction/vulgar-extractor/badwords.txt\") \n",
    "    dftext = df[['text']]\n",
    "    result = dftext.applymap(lambda x: VulgarExtractor.containsVulgar(x,wordlist))\n",
    "    df['isVulgar'] = result\n",
    "\n",
    "    word_embeddings = [ee.tweetVec(tagged_line) for tagged_line in df['text']]\n",
    "    textlist = [txt.replace('\\n','') for txt in df['text'].tolist()]\n",
    "    tagged_sents = TwitterParser.tag(textlist)\n",
    "    df['POS'] = tagged_sents\n",
    "\n",
    "    processed_sents = []\n",
    "    for tagged_sent in df['POS']:\n",
    "        processed_words = []\n",
    "        for word, tag in tagged_sent:\n",
    "            if tag == 'U':\n",
    "                processed_words.append('someurl')\n",
    "            elif tag == '@':\n",
    "                processed_words.append('@someuser')\n",
    "            else:\n",
    "                processed_words.append(word)\n",
    "        sent = ' '.join(processed_words)\n",
    "        processed_sents.append(sent)\n",
    "    df['text'] = processed_sents\n",
    "\n",
    "    word_counts = [TwitterParser.word_count(tagged_line) for tagged_line in df['POS']]\n",
    "    pos_count_list = [TwitterParser.pos_counts(tagged_line) for tagged_line in df['POS']]\n",
    "    contains_adjs = [TwitterParser.contains_adjectives(tagged_line) for tagged_line in df['POS']]\n",
    "    contains_urls = [TwitterParser.contains_url(tagged_line) for tagged_line in df['POS']]\n",
    "    contains_emojis = [TwitterParser.contains_emoji(tagged_line) for tagged_line in df['POS']]\n",
    "    contains_abbrevs = [TwitterParser.contains_abbreviation(tagged_line) for tagged_line in df['POS']]\n",
    "\n",
    "    df['wordCount'] = word_counts\n",
    "    df['posCounts'] = pos_count_list\n",
    "    df['containsAdjective'] = contains_adjs\n",
    "    df['containsURL'] = contains_urls\n",
    "    df['containsEmoji'] = contains_emojis\n",
    "    df['containsAbbreviation'] = contains_abbrevs\n",
    "    df['wordEmbedding'] = word_embeddings\n",
    "\n",
    "    \n",
    "    for i, tag in enumerate(TwitterParser.tagset):\n",
    "        tag_counts = []\n",
    "        for pos_counts in df['posCounts']:\n",
    "            tag_counts.append(pos_counts[i])\n",
    "        column_name = 'num_' + tag\n",
    "        df[column_name] = tag_counts\n",
    "        normalize(column_name, df)\n",
    "        \n",
    "    # Changes \"true\"/\"false\"/\"unverified\" to numeric values, just like the in the early cells\n",
    "    df.loc[df.classification == 'true', 'classification'] = 1\n",
    "    df.loc[df.classification == 'false', 'classification'] = 0\n",
    "    df.loc[df.classification == 'unverified', 'classification'] = 2\n",
    "    # getting the labels\n",
    "\n",
    "    #removed containsURL\n",
    "    attributes = ['isVulgar', 'containsAdjective', 'containsURL', 'containsEmoji', 'containsAbbreviation', 'wordCount']\n",
    "    for tag in TwitterParser.tagset:\n",
    "        attributes.append('num_' + tag)\n",
    "\n",
    "    labels = df['classification']\n",
    "    labels = [l for l in labels]\n",
    "    labels = np.array(labels)\n",
    "\n",
    "\n",
    "    # getting the values as a list of lists\n",
    "    values = df[attributes].values.tolist()\n",
    "    word_embedding_values = df['wordEmbedding'].values.tolist()\n",
    "\n",
    "\n",
    "#     #Below puts the tweet ID as a feature. Comment this out if you aren't using tweetID\n",
    "#     for i,index in enumerate(df.index):\n",
    "#        dev_values[i].append(int(index))\n",
    "\n",
    "\n",
    "#UNCOMMENT THIS IN ORDER TO INCOPORATE WORD_EMBEDDINGS AGAIN\n",
    "    for i,d in enumerate(word_embedding_values):\n",
    "       values[i].extend(d)\n",
    "\n",
    "    values = np.array(values)\n",
    "    if index == 1:\n",
    "        return df.index, values\n",
    "    \n",
    "\n",
    "    \n",
    "    return labels, values\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that the indices of labels-to-values should not be mismatched\n",
    "tr_labels, tr_values = labels_and_vectors('output/simple/train_data_simple.pickle')\n",
    "indices, dev_values,= labels_and_vectors('output/simple/goldtest_data_simple.pickle', index=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change classifier here\n",
    "predictions, probabilities = classifiers.naive_bayes(tr_values, tr_labels, dev_values)\n",
    "ps = []\n",
    "\n",
    "# need to convert the numerical predictions back into their string values\n",
    "for i, p in enumerate(predictions):\n",
    "    if p == 0:\n",
    "        ps.append('false')\n",
    "    if p == 1:\n",
    "        ps.append('true')\n",
    "    if p == 2:\n",
    "        ps.append('unverified')\n",
    "\n",
    "# creates pairings of the prediction and the probability of the prediction\n",
    "pred_probs_pairs = [[ps[i], probabilities[i][predictions[i]]] for i in range(len(predictions))] \n",
    "#attaches the tweetID (called reference_id in the score.py file)\n",
    "pred_dict = {index:pred_probs_pairs[i] for i,index in enumerate(indices)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('output/classifier_output/goldtest_nb.json', 'w') as outfile:\n",
    "    json.dump(pred_dict, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 entries in reference file\n",
      "matching entry: 775057555865206784\n",
      "matching entry: 498486826269548545\n",
      "matching entry: 774991078265094144\n",
      "matching entry: 524948206023880704\n",
      "matching entry: 769988636754505729\n",
      "matching entry: 544315472075042818\n",
      "matching entry: 524936793633083394\n",
      "matching entry: 553561170637238272\n",
      "matching entry: 763098277986209792\n",
      "matching entry: 498293668655423488\n",
      "matching entry: 524941720249978880\n",
      "matching entry: 553553288625672192\n",
      "matching entry: 764927075522260992\n",
      "matching entry: 544274544174071809\n",
      "matching entry: 758159624122097664\n",
      "matching entry: 552788945017516032\n",
      "matching entry: 500280249629036544\n",
      "matching entry: 580352273001410560\n",
      "matching entry: 500298588992593920\n",
      "matching entry: 524923293711998976\n",
      "matching entry: 553480082996879360\n",
      "matching entry: 544294893146091520\n",
      "matching entry: 767725956706414592\n",
      "matching entry: 581153923987206146\n",
      "matching entry: 581359544682614784\n",
      "matching entry: 524961721744900097\n",
      "matching entry: 768859780240773121\n",
      "matching entry: 581290271997968384\n",
      "28 matched entries in submission\n",
      "28 entries in reference file\n",
      "veracity accuracy: 0.5\n",
      "Micro F1: 0.5\n",
      "confidence rmse:   0.7071067811865476\n"
     ]
    }
   ],
   "source": [
    "!python3 scorer/score.py data/semeval2017-task8-dataset/goldtest/subtaskb.json output/classifier_output/goldtest_nb.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
